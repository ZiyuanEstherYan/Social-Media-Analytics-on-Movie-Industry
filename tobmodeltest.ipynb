{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Movie Success/Flop using Movie Attributes and Social Media Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from easymoney.money import EasyPeasy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_org = pd.read_csv('data_concat/brands_with_extras_kmodes.csv')\n",
    "movies_bo = pd.read_csv('data/movie_data_w_bo_fixed.csv')\n",
    "fb_rollup1 = pd.read_csv('/home/jovyan/capstone_data/listenfirst/data/view_brand_rollup_facebook_1k-10k.tsv', delimiter='\\t')\n",
    "fb_rollup2 = pd.read_csv('/home/jovyan/capstone_data/listenfirst/data/view_brand_rollup_facebook_10kplus.tsv', delimiter='\\t')\n",
    "\n",
    "fb = pd.concat([fb_rollup1, fb_rollup2])\n",
    "\n",
    "twitter_rollup1 = pd.read_csv('/home/jovyan/capstone_data/listenfirst/data/view_brand_rollup_twitter_1k-10k.tsv', delimiter='\\t')\n",
    "twitter_rollup2 = pd.read_csv('/home/jovyan/capstone_data/listenfirst/data/view_brand_rollup_twitter_10kplus.tsv', delimiter='\\t')\n",
    "\n",
    "twitter = pd.concat([twitter_rollup1, twitter_rollup2])\n",
    "\n",
    "insta_rollup1 = pd.read_csv('/home/jovyan/capstone_data/listenfirst/data/view_brand_rollup_instagram_1k-10k.tsv', delimiter='\\t')\n",
    "insta_rollup2 = pd.read_csv('/home/jovyan/capstone_data/listenfirst/data/view_brand_rollup_instagram_10kplus.tsv', delimiter='\\t')\n",
    "\n",
    "instagram = pd.concat([insta_rollup1, insta_rollup2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Movie attribute data, clean and bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.merge(movies_org, movies_bo, left_on='replace', right_on='Movie')\n",
    "ep = EasyPeasy()\n",
    "\n",
    "movies['inflated_boxoffice'] = [ep.normalize(amount=x[1]['DomesticGross_y'], region=\"US\", base_currency=\"USD\", from_year=x[1]['released_year'], to_year=\"latest\") for x in movies.iterrows()]\n",
    "movies['inflated_boxoffice'] = movies['inflated_boxoffice'].astype(int)\n",
    "movies_fil = movies[['brand_ods_id', 'replace', 'released_on', 'released_year', 'year_bin',\n",
    "       'production_company', 'rating', 'source', 'franchise',\n",
    "       'genre_grouped', 'inflated_budget', 'inflated_boxoffice', 'production_company_bin']]\n",
    "movies_fil['released_on'] = pd.to_datetime(movies_fil['released_on'])\n",
    "movies_fil['released_month'] = movies_fil['released_on'].map(lambda x: x.month)\n",
    "movies_fil['inflated_profit'] = movies_fil['inflated_boxoffice'] - movies_fil['inflated_budget']\n",
    "movies_fil['profit_bins'] = pd.qcut(movies_fil['inflated_profit'],  q= 3,\n",
    "                             labels=['Flop', 'Medium Profit', 'Insane Profit'])\n",
    "movies_fil['successflop'] = pd.qcut(movies_fil['inflated_profit'],  q=[0, .3, 1],\n",
    "                              labels=['Flop', 'Success'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating Social Media Data from 1 year to 3 months before release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb.columns = ['movie_id', 'data_for'] + [str(col) + '_facebook' for col in fb.columns[2:]]\n",
    "fb_merged = pd.merge(fb, movies_fil, left_on = 'movie_id', right_on = 'brand_ods_id', how = 'left')\n",
    "fb_dropped = fb_merged.dropna(subset=['replace'])\n",
    "fb_dropped['data_for']= pd.to_datetime(fb_dropped['data_for']) \n",
    "fb_dropped['released_on'] = pd.to_datetime(fb_dropped['released_on'])\n",
    "fb_dropped['days_after_release'] = fb_dropped['data_for'] - fb_dropped['released_on'] \n",
    "fb_fil = fb_dropped[(fb_dropped['days_after_release'] <= '-90 days') & (fb_dropped['days_after_release'] >= '-365 days')]\n",
    "fb_grouped = fb_fil.groupby('movie_id', as_index = False).agg('mean')\n",
    "\n",
    "fb_grouped = fb_grouped.drop(['brand_ods_id',\n",
    "       'released_year', 'year_bin', 'inflated_budget', 'inflated_boxoffice',\n",
    "       'released_month', 'inflated_profit'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter.columns = ['movie_id', 'data_for'] + [str(col) + '_twitter' for col in twitter.columns[2:]]\n",
    "twitter_merged = pd.merge(twitter, movies_fil, left_on = 'movie_id', right_on = 'brand_ods_id', how = 'left')\n",
    "twitter_dropped = twitter_merged.dropna(subset=['replace'])\n",
    "twitter_dropped['data_for']= pd.to_datetime(twitter_dropped['data_for']) \n",
    "twitter_dropped['released_on'] = pd.to_datetime(twitter_dropped['released_on'])\n",
    "twitter_dropped['days_after_release'] = twitter_dropped['data_for'] - twitter_dropped['released_on'] \n",
    "twitter_fil = twitter_dropped[(twitter_dropped['days_after_release'] <= '-90 days') & (twitter_dropped['days_after_release'] >= '-365 days')]\n",
    "\n",
    "twitter_grouped = twitter_fil.groupby('movie_id', as_index = False).agg('mean')\n",
    "twitter_grouped = twitter_grouped.drop(['brand_ods_id',\n",
    "       'released_year', 'year_bin', 'inflated_budget', 'inflated_boxoffice',\n",
    "       'released_month', 'inflated_profit'], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "instagram.columns = ['movie_id', 'data_for'] + [str(col) + '_instagram' for col in instagram.columns[2:]]\n",
    "instagram_merged = pd.merge(instagram, movies_fil, left_on = 'movie_id', right_on = 'brand_ods_id', how = 'left')\n",
    "instagram_dropped = instagram_merged.dropna(subset=['replace'])\n",
    "instagram_dropped['data_for']= pd.to_datetime(instagram_dropped['data_for']) \n",
    "instagram_dropped['released_on'] = pd.to_datetime(instagram_dropped['released_on'])\n",
    "instagram_dropped['days_after_release'] = instagram_dropped['data_for'] - instagram_dropped['released_on'] \n",
    "instagram_fil = instagram_dropped[(instagram_dropped['days_after_release'] <= '-90 days') & (instagram_dropped['days_after_release'] >= '-365 days')]\n",
    "instagram_grouped = instagram_fil.groupby('movie_id', as_index = False).agg('mean')\n",
    "\n",
    "instagram_grouped = instagram_grouped.drop(['brand_ods_id',\n",
    "       'released_year', 'year_bin', 'inflated_budget', 'inflated_boxoffice',\n",
    "       'released_month', 'inflated_profit'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Movie attribute data with social media data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_fil = pd.merge(movies_fil, fb_grouped, left_on = 'brand_ods_id', right_on = 'movie_id', how = 'left')\n",
    "movies_fil = pd.merge(movies_fil, twitter_grouped, left_on = 'movie_id', right_on = 'movie_id', how = 'left')\n",
    "movies_fil = pd.merge(movies_fil, instagram_grouped, left_on = 'movie_id', right_on = 'movie_id', how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NAN cells with 0\n",
    "movies_fil.update(movies_fil[['likes_c_facebook', 'likes_facebook',\n",
    "       'talking_about_c_facebook', 'talking_about_facebook',\n",
    "       'engagement_rate_c_facebook', 'engagement_rate_facebook',\n",
    "       'total_post_c_facebook', 'total_post_facebook',\n",
    "       'total_post_likes_c_facebook', 'total_post_likes_facebook',\n",
    "       'total_post_shares_c_facebook', 'total_post_shares_facebook',\n",
    "       'total_post_comments_c_facebook', 'total_post_comments_facebook',\n",
    "       'total_post_love_count_c_facebook', 'total_post_love_count_facebook',\n",
    "       'total_post_wow_count_c_facebook', 'total_post_wow_count_facebook',\n",
    "       'total_post_haha_count_c_facebook', 'total_post_haha_count_facebook',\n",
    "       'total_post_sad_count_c_facebook', 'total_post_sad_count_facebook',\n",
    "       'total_post_angry_count_c_facebook', 'total_post_angry_count_facebook',\n",
    "       'total_post_thankful_count_c_facebook',\n",
    "       'total_post_thankful_count_facebook',\n",
    "       'total_post_tracked_reactions_c_facebook',\n",
    "       'total_post_tracked_reactions_facebook',\n",
    "       'total_post_reactions_count_c_facebook',\n",
    "       'total_post_reactions_count_facebook',\n",
    "       'total_post_interactions_c_facebook',\n",
    "       'total_post_interactions_facebook', 'total_post_video_c_facebook',\n",
    "       'total_post_video_facebook', 'total_post_video_interactions_c_facebook',\n",
    "       'total_post_video_interactions_facebook', 'tweets_c_twitter',\n",
    "       'tweets_twitter', 'followers_c_twitter', 'followers_twitter',\n",
    "       'mentions_twitter', 'total_mentions_twitter',\n",
    "       'total_retweets_c_twitter', 'total_retweets_twitter',\n",
    "       'total_favorites_c_twitter', 'total_favorites_twitter',\n",
    "       'total_replies_c_twitter', 'total_replies_twitter',\n",
    "       'tracked_posts_c_twitter', 'tracked_posts_twitter',\n",
    "       'video_tracked_posts_c_twitter', 'video_tracked_posts_twitter',\n",
    "       'video_retweets_c_twitter', 'video_retweets_twitter',\n",
    "       'video_favorites_c_twitter', 'video_favorites_twitter',\n",
    "       'video_replies_c_twitter', 'video_replies_twitter',\n",
    "       'video_views_c_twitter', 'video_views_twitter',\n",
    "       'total_post_interactions_c_twitter', 'total_post_interactions_twitter',\n",
    "       'hashtag_volume_twitter', 'keyword_volume_twitter',\n",
    "       'cashtag_volume_twitter', 'avg_tweet_interaction_twitter',\n",
    "       'media_count_c_instagram', 'media_count_instagram',\n",
    "       'tracked_posts_c_instagram', 'tracked_posts_instagram',\n",
    "       'followed_by_count_c_instagram', 'followed_by_count_instagram',\n",
    "       'follows_count_c_instagram', 'follows_count_instagram',\n",
    "       'total_likes_c_instagram', 'total_likes_instagram',\n",
    "       'total_comments_c_instagram', 'total_comments_instagram',\n",
    "       'total_post_interactions_c_instagram',\n",
    "       'total_post_interactions_instagram',\n",
    "       'avg_interactions_per_post_c_instagram',\n",
    "       'avg_interactions_per_post_instagram']].fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing DataFrames for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Dataframe with Movie Attributes and Social Media Data (movies_test)\n",
    "movies_test = movies_fil[['rating', 'source', 'franchise', 'genre_grouped',\n",
    "       'inflated_budget', 'production_company_bin',\n",
    "       'released_month', 'likes_c_facebook', 'likes_facebook',\n",
    "       'talking_about_c_facebook', 'talking_about_facebook',\n",
    "       'engagement_rate_c_facebook', 'engagement_rate_facebook',\n",
    "       'total_post_c_facebook', 'total_post_facebook',\n",
    "       'total_post_likes_c_facebook', 'total_post_likes_facebook',\n",
    "       'total_post_shares_c_facebook', 'total_post_shares_facebook',\n",
    "       'total_post_comments_c_facebook', 'total_post_comments_facebook',\n",
    "       'total_post_love_count_c_facebook', 'total_post_love_count_facebook',\n",
    "       'total_post_wow_count_c_facebook', 'total_post_wow_count_facebook',\n",
    "       'total_post_haha_count_c_facebook', 'total_post_haha_count_facebook',\n",
    "       'total_post_sad_count_c_facebook', 'total_post_sad_count_facebook',\n",
    "       'total_post_angry_count_c_facebook', 'total_post_angry_count_facebook',\n",
    "       'total_post_thankful_count_c_facebook',\n",
    "       'total_post_thankful_count_facebook',\n",
    "       'total_post_tracked_reactions_c_facebook',\n",
    "       'total_post_tracked_reactions_facebook',\n",
    "       'total_post_reactions_count_c_facebook',\n",
    "       'total_post_reactions_count_facebook',\n",
    "       'total_post_interactions_c_facebook',\n",
    "       'total_post_interactions_facebook', 'total_post_video_c_facebook',\n",
    "       'total_post_video_facebook', 'total_post_video_interactions_c_facebook',\n",
    "       'total_post_video_interactions_facebook', 'tweets_c_twitter',\n",
    "       'tweets_twitter', 'followers_c_twitter', 'followers_twitter',\n",
    "       'mentions_twitter', 'total_mentions_twitter',\n",
    "       'total_retweets_c_twitter', 'total_retweets_twitter',\n",
    "       'total_favorites_c_twitter', 'total_favorites_twitter',\n",
    "       'total_replies_c_twitter', 'total_replies_twitter',\n",
    "       'tracked_posts_c_twitter', 'tracked_posts_twitter',\n",
    "       'video_tracked_posts_c_twitter', 'video_tracked_posts_twitter',\n",
    "       'video_retweets_c_twitter', 'video_retweets_twitter',\n",
    "       'video_favorites_c_twitter', 'video_favorites_twitter',\n",
    "       'video_replies_c_twitter', 'video_replies_twitter',\n",
    "       'video_views_c_twitter', 'video_views_twitter',\n",
    "       'total_post_interactions_c_twitter', 'total_post_interactions_twitter',\n",
    "       'hashtag_volume_twitter', 'keyword_volume_twitter',\n",
    "       'cashtag_volume_twitter', 'avg_tweet_interaction_twitter',\n",
    "       'media_count_c_instagram', 'media_count_instagram',\n",
    "       'tracked_posts_c_instagram', 'tracked_posts_instagram',\n",
    "       'followed_by_count_c_instagram', 'followed_by_count_instagram',\n",
    "       'follows_count_c_instagram', 'follows_count_instagram',\n",
    "       'total_likes_c_instagram', 'total_likes_instagram',\n",
    "       'total_comments_c_instagram', 'total_comments_instagram',\n",
    "       'total_post_interactions_c_instagram',\n",
    "       'total_post_interactions_instagram',\n",
    "       'avg_interactions_per_post_c_instagram',\n",
    "       'avg_interactions_per_post_instagram',  'successflop']]\n",
    "\n",
    "#Defining Dataframe with only Budget and Social Media Data (movies_final)\n",
    "movies_final = movies_fil[['inflated_budget', 'likes_c_facebook', 'likes_facebook',\n",
    "       'talking_about_c_facebook', 'talking_about_facebook',\n",
    "       'engagement_rate_c_facebook', 'engagement_rate_facebook',\n",
    "       'total_post_c_facebook', 'total_post_facebook',\n",
    "       'total_post_likes_c_facebook', 'total_post_likes_facebook',\n",
    "       'total_post_shares_c_facebook', 'total_post_shares_facebook',\n",
    "       'total_post_comments_c_facebook', 'total_post_comments_facebook',\n",
    "       'total_post_love_count_c_facebook', 'total_post_love_count_facebook',\n",
    "       'total_post_wow_count_c_facebook', 'total_post_wow_count_facebook',\n",
    "       'total_post_haha_count_c_facebook', 'total_post_haha_count_facebook',\n",
    "       'total_post_sad_count_c_facebook', 'total_post_sad_count_facebook',\n",
    "       'total_post_angry_count_c_facebook', 'total_post_angry_count_facebook',\n",
    "       'total_post_thankful_count_c_facebook',\n",
    "       'total_post_thankful_count_facebook',\n",
    "       'total_post_tracked_reactions_c_facebook',\n",
    "       'total_post_tracked_reactions_facebook',\n",
    "       'total_post_reactions_count_c_facebook',\n",
    "       'total_post_reactions_count_facebook',\n",
    "       'total_post_interactions_c_facebook',\n",
    "       'total_post_interactions_facebook', 'total_post_video_c_facebook',\n",
    "       'total_post_video_facebook', 'total_post_video_interactions_c_facebook',\n",
    "       'total_post_video_interactions_facebook', 'tweets_c_twitter',\n",
    "       'tweets_twitter', 'followers_c_twitter', 'followers_twitter',\n",
    "       'mentions_twitter', 'total_mentions_twitter',\n",
    "       'total_retweets_c_twitter', 'total_retweets_twitter',\n",
    "       'total_favorites_c_twitter', 'total_favorites_twitter',\n",
    "       'total_replies_c_twitter', 'total_replies_twitter',\n",
    "       'tracked_posts_c_twitter', 'tracked_posts_twitter',\n",
    "       'video_tracked_posts_c_twitter', 'video_tracked_posts_twitter',\n",
    "       'video_retweets_c_twitter', 'video_retweets_twitter',\n",
    "       'video_favorites_c_twitter', 'video_favorites_twitter',\n",
    "       'video_replies_c_twitter', 'video_replies_twitter',\n",
    "       'video_views_c_twitter', 'video_views_twitter',\n",
    "       'total_post_interactions_c_twitter', 'total_post_interactions_twitter',\n",
    "       'hashtag_volume_twitter', 'keyword_volume_twitter',\n",
    "       'cashtag_volume_twitter', 'avg_tweet_interaction_twitter',\n",
    "       'media_count_c_instagram', 'media_count_instagram',\n",
    "       'tracked_posts_c_instagram', 'tracked_posts_instagram',\n",
    "       'followed_by_count_c_instagram', 'followed_by_count_instagram',\n",
    "       'follows_count_c_instagram', 'follows_count_instagram',\n",
    "       'total_likes_c_instagram', 'total_likes_instagram',\n",
    "       'total_comments_c_instagram', 'total_comments_instagram',\n",
    "       'total_post_interactions_c_instagram',\n",
    "       'total_post_interactions_instagram',\n",
    "       'avg_interactions_per_post_c_instagram',\n",
    "       'avg_interactions_per_post_instagram',  'successflop']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "  \n",
    "le = LabelEncoder() \n",
    "\n",
    "movies_test[\"rating\"] = movies_test[\"rating\"].astype('category')\n",
    "movies_test[\"source\"] = movies_test[\"source\"].astype('category')\n",
    "movies_test[\"franchise\"] = movies_test[\"franchise\"].astype('category')\n",
    "movies_test[\"genre_grouped\"] = movies_test[\"genre_grouped\"].astype('category')\n",
    "movies_test[\"production_company_bin\"] = movies_test[\"production_company_bin\"].astype('category')\n",
    "movies_test[\"released_month\"] = movies_test[\"released_month\"].astype('category')\n",
    "movies_test[\"successflop\"] = movies_test[\"successflop\"].astype('category')\n",
    "\n",
    "\n",
    "movies_test[\"rating\"] = le.fit_transform(movies_test[\"rating\"])\n",
    "movies_test[\"source\"] = le.fit_transform(movies_test[\"source\"])\n",
    "movies_test[\"franchise\"] = le.fit_transform(movies_test[\"franchise\"])\n",
    "movies_test[\"genre_grouped\"] = le.fit_transform(movies_test[\"genre_grouped\"])\n",
    "movies_test[\"production_company_bin\"] = le.fit_transform(movies_test[\"production_company_bin\"])\n",
    "movies_test[\"released_month\"] = le.fit_transform(movies_test[\"released_month\"])\n",
    "movies_test[\"successflop\"] = le.fit_transform(movies_test[\"successflop\"])\n",
    "\n",
    "movies_final[\"successflop\"] = movies_final[\"successflop\"].astype('category')\n",
    "movies_final[\"successflop\"] = le.fit_transform(movies_final[\"successflop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'source', 'franchise', 'genre_grouped', 'inflated_budget',\n",
       "       'production_company_bin', 'released_month', 'likes_c_facebook',\n",
       "       'likes_facebook', 'talking_about_c_facebook', 'talking_about_facebook',\n",
       "       'engagement_rate_c_facebook', 'engagement_rate_facebook',\n",
       "       'total_post_c_facebook', 'total_post_facebook',\n",
       "       'total_post_likes_c_facebook', 'total_post_likes_facebook',\n",
       "       'total_post_shares_c_facebook', 'total_post_shares_facebook',\n",
       "       'total_post_comments_c_facebook', 'total_post_comments_facebook',\n",
       "       'total_post_love_count_c_facebook', 'total_post_love_count_facebook',\n",
       "       'total_post_wow_count_c_facebook', 'total_post_wow_count_facebook',\n",
       "       'total_post_haha_count_c_facebook', 'total_post_haha_count_facebook',\n",
       "       'total_post_sad_count_c_facebook', 'total_post_sad_count_facebook',\n",
       "       'total_post_angry_count_c_facebook', 'total_post_angry_count_facebook',\n",
       "       'total_post_thankful_count_c_facebook',\n",
       "       'total_post_thankful_count_facebook',\n",
       "       'total_post_tracked_reactions_c_facebook',\n",
       "       'total_post_tracked_reactions_facebook',\n",
       "       'total_post_reactions_count_c_facebook',\n",
       "       'total_post_reactions_count_facebook',\n",
       "       'total_post_interactions_c_facebook',\n",
       "       'total_post_interactions_facebook', 'total_post_video_c_facebook',\n",
       "       'total_post_video_facebook', 'total_post_video_interactions_c_facebook',\n",
       "       'total_post_video_interactions_facebook', 'tweets_c_twitter',\n",
       "       'tweets_twitter', 'followers_c_twitter', 'followers_twitter',\n",
       "       'mentions_twitter', 'total_mentions_twitter',\n",
       "       'total_retweets_c_twitter', 'total_retweets_twitter',\n",
       "       'total_favorites_c_twitter', 'total_favorites_twitter',\n",
       "       'total_replies_c_twitter', 'total_replies_twitter',\n",
       "       'tracked_posts_c_twitter', 'tracked_posts_twitter',\n",
       "       'video_tracked_posts_c_twitter', 'video_tracked_posts_twitter',\n",
       "       'video_retweets_c_twitter', 'video_retweets_twitter',\n",
       "       'video_favorites_c_twitter', 'video_favorites_twitter',\n",
       "       'video_replies_c_twitter', 'video_replies_twitter',\n",
       "       'video_views_c_twitter', 'video_views_twitter',\n",
       "       'total_post_interactions_c_twitter', 'total_post_interactions_twitter',\n",
       "       'hashtag_volume_twitter', 'keyword_volume_twitter',\n",
       "       'cashtag_volume_twitter', 'avg_tweet_interaction_twitter',\n",
       "       'media_count_c_instagram', 'media_count_instagram',\n",
       "       'tracked_posts_c_instagram', 'tracked_posts_instagram',\n",
       "       'followed_by_count_c_instagram', 'followed_by_count_instagram',\n",
       "       'follows_count_c_instagram', 'follows_count_instagram',\n",
       "       'total_likes_c_instagram', 'total_likes_instagram',\n",
       "       'total_comments_c_instagram', 'total_comments_instagram',\n",
       "       'total_post_interactions_c_instagram',\n",
       "       'total_post_interactions_instagram',\n",
       "       'avg_interactions_per_post_c_instagram',\n",
       "       'avg_interactions_per_post_instagram', 'successflop'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movies with only Numerical Features (movies_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract top 10 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Specs      Score\n",
      "0                       inflated_budget  11.378469\n",
      "13       total_post_comments_c_facebook   5.246370\n",
      "19     total_post_haha_count_c_facebook   4.723727\n",
      "4                talking_about_facebook   4.503240\n",
      "6              engagement_rate_facebook   4.497621\n",
      "63               hashtag_volume_twitter   4.480371\n",
      "82  avg_interactions_per_post_instagram   4.028047\n",
      "20       total_post_haha_count_facebook   3.939283\n",
      "42               total_mentions_twitter   3.579434\n",
      "66        avg_tweet_interaction_twitter   3.398552\n"
     ]
    }
   ],
   "source": [
    "# Extracting using ANOVA F-values\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "X = movies_final.iloc[:,0:83]  #feature columns\n",
    "y = movies_final.iloc[:,-1]    #label columns\n",
    "\n",
    "#Use SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06217124 0.01703576 0.01566984 0.01141177 0.01456505 0.01349112\n",
      " 0.02111437 0.01345874 0.02522057 0.01263315 0.01204776 0.01329992\n",
      " 0.01152203 0.0142988  0.01038803 0.01010132 0.00981556 0.01255598\n",
      " 0.0109487  0.01164565 0.00860687 0.01017502 0.00772029 0.00976307\n",
      " 0.00865971 0.00546885 0.00436079 0.01041834 0.01136505 0.01226136\n",
      " 0.01228191 0.01292014 0.0102155  0.01487935 0.01179946 0.01266248\n",
      " 0.01139369 0.01984311 0.01643898 0.01449079 0.01523706 0.01451014\n",
      " 0.02346602 0.01490179 0.01260353 0.0116754  0.01155328 0.00738704\n",
      " 0.00755501 0.01421257 0.01210111 0.0130487  0.00995893 0.00929813\n",
      " 0.01052745 0.00881454 0.01104093 0.00657719 0.00809152 0.0084775\n",
      " 0.01012956 0.01248945 0.01161935 0.02423672 0.         0.\n",
      " 0.01319804 0.00993382 0.00997223 0.01035749 0.01056134 0.00997665\n",
      " 0.00770708 0.01005962 0.0097166  0.00631445 0.00803845 0.00963477\n",
      " 0.0080014  0.00925742 0.00950195 0.00887752 0.01025816]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparing ANOVA with using Feature Importance of Extra Trees Classifier\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing features and trying models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_final_sel = movies_final[['inflated_budget',\n",
    "       'total_post_comments_c_facebook',\n",
    "     'total_post_haha_count_c_facebook',\n",
    "                'talking_about_facebook',\n",
    "              'engagement_rate_facebook',\n",
    "               'hashtag_volume_twitter',\n",
    "  'avg_interactions_per_post_instagram',\n",
    "       'total_post_haha_count_facebook',\n",
    "               'total_mentions_twitter',\n",
    "        'avg_tweet_interaction_twitter', 'successflop']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Models\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import export_graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting Dataset into train and test\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# test_size: what proportion of original data is used for test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "   movies_final_sel.loc[:,movies_final_sel.columns != 'successflop'] ,movies_final_sel[['successflop']], random_state=1234, test_size=0.30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inflated_budget</td>\n",
       "      <td>0.204857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>engagement_rate_facebook</td>\n",
       "      <td>0.112875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>avg_tweet_interaction_twitter</td>\n",
       "      <td>0.106599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>talking_about_facebook</td>\n",
       "      <td>0.106105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_post_comments_c_facebook</td>\n",
       "      <td>0.100410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hashtag_volume_twitter</td>\n",
       "      <td>0.085415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total_mentions_twitter</td>\n",
       "      <td>0.083751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_post_haha_count_facebook</td>\n",
       "      <td>0.072553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>avg_interactions_per_post_instagram</td>\n",
       "      <td>0.069169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_post_haha_count_c_facebook</td>\n",
       "      <td>0.058266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              features  importance\n",
       "0                      inflated_budget    0.204857\n",
       "4             engagement_rate_facebook    0.112875\n",
       "9        avg_tweet_interaction_twitter    0.106599\n",
       "3               talking_about_facebook    0.106105\n",
       "1       total_post_comments_c_facebook    0.100410\n",
       "5               hashtag_volume_twitter    0.085415\n",
       "8               total_mentions_twitter    0.083751\n",
       "7       total_post_haha_count_facebook    0.072553\n",
       "6  avg_interactions_per_post_instagram    0.069169\n",
       "2     total_post_haha_count_c_facebook    0.058266"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Variable importance for Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "pd.DataFrame({'features' : x_train.columns.to_numpy(), 'importance':rf.feature_importances_}).sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "logistic_model = LogisticRegression(random_state = 0)\n",
    "# Model Fitting on Training\n",
    "logistic_model = logistic_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(logistic_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(logistic_model.predict_proba(x_test))\n",
    "\n",
    "logistic_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "logistic_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "logistic_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "logistic_class_report = metrics.classification_report(y_test, predicted)\n",
    "logistic_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "logistic_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "logistic_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "logistic_cv_score = cross_val_score(LogisticRegression(), x_test, y_test, scoring='accuracy', cv=10)\n",
    "logistic_cv_mean = np.mean(logistic_cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24, 26],\n",
       "       [35, 77]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "dtree_model = tree.DecisionTreeClassifier(max_depth=3) \n",
    "\n",
    "# Model Fitting on Training\n",
    "dtree_model = dtree_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(dtree_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(dtree_model.predict_proba(x_test))\n",
    "\n",
    "dtree_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "dtree_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "dtree_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "dtree_class_report = metrics.classification_report(y_test, predicted)\n",
    "dtree_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "dtree_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "dtree_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "dtree_cv_score = cross_val_score(tree.DecisionTreeClassifier(max_depth=3), x_test, y_test, scoring='accuracy', cv=10)\n",
    "dtree_cv_mean = np.mean(dtree_cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "rf_model = RandomForestClassifier() \n",
    "\n",
    "# Model Fitting on Training\n",
    "rf_model = rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(rf_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(rf_model.predict_proba(x_test))\n",
    "\n",
    "rf_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "rf_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "rf_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "rf_class_report = metrics.classification_report(y_test, predicted)\n",
    "rf_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "rf_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "rf_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "rf_cv_scores = cross_val_score(RandomForestClassifier(), x_test, y_test, scoring='accuracy', cv=10)\n",
    "rf_cv_mean = np.mean(rf_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "\n",
    "svm_class_model = SVC(probability=True)\n",
    "\n",
    "# Model Fitting on Training\n",
    "svm_class_model = svm_class_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(svm_class_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(svm_class_model.predict_proba(x_test))\n",
    "\n",
    "svm_class_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "svm_class_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "svm_class_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "svm_class_class_report = metrics.classification_report(y_test, predicted)\n",
    "svm_class_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "svm_class_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "svm_class_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "svm_class_cv_scores = cross_val_score(SVC(probability=True), x_test, y_test, scoring='accuracy', cv=10)\n",
    "svm_class_cv_mean = np.mean(svm_class_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5500757575757577"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Model Fitting on Training\n",
    "knn_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(knn_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(knn_model.predict_proba(x_test))\n",
    "\n",
    "knn_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "knn_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "knn_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "knn_class_report = metrics.classification_report(y_test, predicted)\n",
    "knn_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "knn_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "knn_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "knn_cv_scores = cross_val_score(KNeighborsClassifier(n_neighbors=3), x_test, y_test, scoring='balanced_accuracy', cv=10)\n",
    "knn_cv_mean = np.mean(knn_cv_scores)\n",
    "knn_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32266666666666666"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(10,10, 1))\n",
    "# Fit the model\n",
    "mlp_model.fit(x_train, y_train)\n",
    "# Accuracy\n",
    "mlp_model.score(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4713235294117647"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions/probs on the test dataset\n",
    "predicted = pd.DataFrame(mlp_model.predict(x_test))\n",
    "probs = pd.DataFrame(mlp_model.predict_proba(x_test))\n",
    "\n",
    "mlp_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "mlp_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "mlp_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "mlp_class_report = metrics.classification_report(y_test, predicted)\n",
    "mlp_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "mlp_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "mlp_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "mlp_cv_scores = cross_val_score(mlp_model, x_test, y_test, scoring='accuracy', cv=10)\n",
    "mlp_cv_mean = np.mean(mlp_cv_scores)\n",
    "mlp_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>cv_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817518</td>\n",
       "      <td>0.678676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r.f.</td>\n",
       "      <td>0.697531</td>\n",
       "      <td>0.726619</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.804781</td>\n",
       "      <td>0.665809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d.Tree</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.810409</td>\n",
       "      <td>0.659559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.623457</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.716279</td>\n",
       "      <td>0.611397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>0.771784</td>\n",
       "      <td>0.550076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.034783</td>\n",
       "      <td>0.471324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy  Precision    recall        F1  cv_accuracy\n",
       "3       SVM  0.691358   0.691358  1.000000  0.817518     0.678676\n",
       "2      r.f.  0.697531   0.726619  0.901786  0.804781     0.665809\n",
       "1    d.Tree  0.685185   0.694268  0.973214  0.810409     0.659559\n",
       "0  Logistic  0.623457   0.747573  0.687500  0.716279     0.611397\n",
       "4       kNN  0.660494   0.720930  0.830357  0.771784     0.550076\n",
       "5       MLP  0.314815   0.666667  0.017857  0.034783     0.471324"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model comparison\n",
    "models = pd.DataFrame({\n",
    "  'Model': ['Logistic', 'd.Tree', 'r.f.', 'SVM', 'kNN',  'MLP'],\n",
    "  'Accuracy' : [logistic_acc, dtree_acc, rf_acc, svm_class_acc, knn_acc, mlp_acc],\n",
    "  'Precision': [logistic_precision_score, dtree_precision_score, rf_precision_score, svm_class_precision_score, knn_precision_score, mlp_precision_score],\n",
    "  'recall' : [logistic_recall_score, dtree_recall_score, rf_recall_score, svm_class_recall_score, knn_recall_score, mlp_recall_score],\n",
    "  'F1' : [logistic_f1_score, dtree_f1_score, rf_f1_score, svm_class_f1_score, knn_f1_score, mlp_f1_score],\n",
    "  'cv_accuracy' : [logistic_cv_mean, dtree_cv_mean, rf_cv_mean, svm_class_cv_mean, knn_cv_mean, mlp_cv_mean]\n",
    "})\n",
    "# Print table and sort by test precision\n",
    "models.sort_values(by='cv_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_final_normalize = movies_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cols = ['inflated_budget', 'likes_c_facebook', 'likes_facebook',\n",
    "       'talking_about_c_facebook', 'talking_about_facebook',\n",
    "       'engagement_rate_c_facebook', 'engagement_rate_facebook',\n",
    "       'total_post_c_facebook', 'total_post_facebook',\n",
    "       'total_post_likes_c_facebook', 'total_post_likes_facebook',\n",
    "       'total_post_shares_c_facebook', 'total_post_shares_facebook',\n",
    "       'total_post_comments_c_facebook', 'total_post_comments_facebook',\n",
    "       'total_post_love_count_c_facebook', 'total_post_love_count_facebook',\n",
    "       'total_post_wow_count_c_facebook', 'total_post_wow_count_facebook',\n",
    "       'total_post_haha_count_c_facebook', 'total_post_haha_count_facebook',\n",
    "       'total_post_sad_count_c_facebook', 'total_post_sad_count_facebook',\n",
    "       'total_post_angry_count_c_facebook', 'total_post_angry_count_facebook',\n",
    "       'total_post_thankful_count_c_facebook',\n",
    "       'total_post_thankful_count_facebook',\n",
    "       'total_post_tracked_reactions_c_facebook',\n",
    "       'total_post_tracked_reactions_facebook',\n",
    "       'total_post_reactions_count_c_facebook',\n",
    "       'total_post_reactions_count_facebook',\n",
    "       'total_post_interactions_c_facebook',\n",
    "       'total_post_interactions_facebook', 'total_post_video_c_facebook',\n",
    "       'total_post_video_facebook', 'total_post_video_interactions_c_facebook',\n",
    "       'total_post_video_interactions_facebook', 'tweets_c_twitter',\n",
    "       'tweets_twitter', 'followers_c_twitter', 'followers_twitter',\n",
    "       'mentions_twitter', 'total_mentions_twitter',\n",
    "       'total_retweets_c_twitter', 'total_retweets_twitter',\n",
    "       'total_favorites_c_twitter', 'total_favorites_twitter',\n",
    "       'total_replies_c_twitter', 'total_replies_twitter',\n",
    "       'tracked_posts_c_twitter', 'tracked_posts_twitter',\n",
    "       'video_tracked_posts_c_twitter', 'video_tracked_posts_twitter',\n",
    "       'video_retweets_c_twitter', 'video_retweets_twitter',\n",
    "       'video_favorites_c_twitter', 'video_favorites_twitter',\n",
    "       'video_replies_c_twitter', 'video_replies_twitter',\n",
    "       'video_views_c_twitter', 'video_views_twitter',\n",
    "       'total_post_interactions_c_twitter', 'total_post_interactions_twitter',\n",
    "       'hashtag_volume_twitter', 'keyword_volume_twitter',\n",
    "       'cashtag_volume_twitter', 'avg_tweet_interaction_twitter',\n",
    "       'media_count_c_instagram', 'media_count_instagram',\n",
    "       'tracked_posts_c_instagram', 'tracked_posts_instagram',\n",
    "       'followed_by_count_c_instagram', 'followed_by_count_instagram',\n",
    "       'follows_count_c_instagram', 'follows_count_instagram',\n",
    "       'total_likes_c_instagram', 'total_likes_instagram',\n",
    "       'total_comments_c_instagram', 'total_comments_instagram',\n",
    "       'total_post_interactions_c_instagram',\n",
    "       'total_post_interactions_instagram',\n",
    "       'avg_interactions_per_post_c_instagram',\n",
    "       'avg_interactions_per_post_instagram']\n",
    "\n",
    "\n",
    "# apply standardization on numerical features\n",
    "    \n",
    "for i in num_cols:\n",
    "    \n",
    "    # fit on training data column\n",
    "    scale = MinMaxScaler().fit(movies_final_normalize[[i]])\n",
    "    \n",
    "    # transform the training data column\n",
    "    movies_final_normalize[i] = scale.transform(movies_final_normalize[[i]])\n",
    "    \n",
    "    # transform the testing data column\n",
    "    movies_final_normalize[i] = scale.transform(movies_final_normalize[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Specs      Score\n",
      "0                       inflated_budget  11.378469\n",
      "13       total_post_comments_c_facebook   5.246370\n",
      "19     total_post_haha_count_c_facebook   4.723727\n",
      "4                talking_about_facebook   4.503240\n",
      "6              engagement_rate_facebook   4.497621\n",
      "63               hashtag_volume_twitter   4.480371\n",
      "82  avg_interactions_per_post_instagram   4.028047\n",
      "20       total_post_haha_count_facebook   3.939283\n",
      "42               total_mentions_twitter   3.579434\n",
      "66        avg_tweet_interaction_twitter   3.398552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "X = movies_final_normalize.iloc[:,0:83]  #independent columns\n",
    "y = movies_final_normalize.iloc[:,-1]    #target column i.e price range\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_final_normalized_sel = movies_final_normalize[['inflated_budget',\n",
    "       'total_post_comments_c_facebook',\n",
    "     'total_post_haha_count_c_facebook',\n",
    "                'talking_about_facebook',\n",
    "              'engagement_rate_facebook',\n",
    "               'hashtag_volume_twitter',\n",
    "  'avg_interactions_per_post_instagram',\n",
    "       'total_post_haha_count_facebook',\n",
    "               'total_mentions_twitter',\n",
    "        'avg_tweet_interaction_twitter', 'successflop']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# test_size: what proportion of original data is used for test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "   movies_final_normalized_sel.loc[:,movies_final_normalized_sel.columns != 'successflop'] ,movies_final_normalized_sel[['successflop']], random_state=1234, test_size=0.30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.253, 'total_post_comments_c_facebook'), (0.1961, 'engagement_rate_facebook'), (0.1731, 'total_post_haha_count_c_facebook'), (0.1652, 'hashtag_volume_twitter'), (0.1242, 'total_mentions_twitter'), (0.0529, 'avg_interactions_per_post_instagram'), (0.0172, 'total_post_haha_count_facebook'), (0.0156, 'avg_tweet_interaction_twitter'), (0.0027, 'talking_about_facebook'), (0.0, 'inflated_budget')]\n"
     ]
    }
   ],
   "source": [
    "# Variable importance\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "print( \"Features sorted by their score:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), x_train), reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_post_comments_c_facebook</td>\n",
       "      <td>0.253030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>engagement_rate_facebook</td>\n",
       "      <td>0.196109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_post_haha_count_c_facebook</td>\n",
       "      <td>0.173101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hashtag_volume_twitter</td>\n",
       "      <td>0.165214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total_mentions_twitter</td>\n",
       "      <td>0.124228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>avg_interactions_per_post_instagram</td>\n",
       "      <td>0.052860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_post_haha_count_facebook</td>\n",
       "      <td>0.017215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>avg_tweet_interaction_twitter</td>\n",
       "      <td>0.015588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>talking_about_facebook</td>\n",
       "      <td>0.002655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inflated_budget</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              features  importance\n",
       "1       total_post_comments_c_facebook    0.253030\n",
       "4             engagement_rate_facebook    0.196109\n",
       "2     total_post_haha_count_c_facebook    0.173101\n",
       "5               hashtag_volume_twitter    0.165214\n",
       "8               total_mentions_twitter    0.124228\n",
       "6  avg_interactions_per_post_instagram    0.052860\n",
       "7       total_post_haha_count_facebook    0.017215\n",
       "9        avg_tweet_interaction_twitter    0.015588\n",
       "3               talking_about_facebook    0.002655\n",
       "0                      inflated_budget    0.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'features' : x_train.columns.to_numpy(), 'importance':rf.feature_importances_}).sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "logistic_model = LogisticRegression(random_state = 0)\n",
    "# Model Fitting on Training\n",
    "logistic_model = logistic_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(logistic_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(logistic_model.predict_proba(x_test))\n",
    "\n",
    "logistic_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "logistic_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "logistic_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "logistic_class_report = metrics.classification_report(y_test, predicted)\n",
    "logistic_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "logistic_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "logistic_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "logistic_cv_score = cross_val_score(LogisticRegression(), x_test, y_test, scoring='accuracy', cv=10)\n",
    "logistic_cv_mean = np.mean(logistic_cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "dtree_model = tree.DecisionTreeClassifier(max_depth=3) \n",
    "# Model Fitting on Training\n",
    "dtree_model = dtree_model.fit(x_train, y_train)\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(dtree_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(dtree_model.predict_proba(x_test))\n",
    "\n",
    "dtree_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "dtree_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "dtree_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "dtree_class_report = metrics.classification_report(y_test, predicted)\n",
    "dtree_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "dtree_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "dtree_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "dtree_cv_score = cross_val_score(tree.DecisionTreeClassifier(max_depth=3), x_test, y_test, scoring='accuracy', cv=10)\n",
    "dtree_cv_mean = np.mean(dtree_cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6349264705882354"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Model\n",
    "rf = RandomForestClassifier() \n",
    "# Model Fitting on Training\n",
    "rf_model = rf.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(rf_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(rf_model.predict_proba(x_test))\n",
    "\n",
    "rf_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "rf_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "rf_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "rf_class_report = metrics.classification_report(y_test, predicted)\n",
    "rf_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "rf_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "rf_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "rf_cv_scores = cross_val_score(RandomForestClassifier(), x_test, y_test, scoring='accuracy', cv=10)\n",
    "rf_cv_mean = np.mean(rf_cv_scores)\n",
    "rf_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6911764705882353"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Model\n",
    "svm_class_model = SVC(probability=True)\n",
    "# Model Fitting on Training\n",
    "svm_class_model = svm_class_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(svm_class_model.predict(x_test))\n",
    "probs = pd.DataFrame(svm_class_model.predict_proba(x_test))\n",
    "\n",
    "# Store metrics\n",
    "svm_class_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "svm_class_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "svm_class_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "svm_class_class_report = metrics.classification_report(y_test, predicted)\n",
    "svm_class_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "svm_class_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "svm_class_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "svm_class_cv_scores = cross_val_score(SVC(probability=True), x_test, y_test, scoring='accuracy', cv=10)\n",
    "svm_class_cv_mean = np.mean(svm_class_cv_scores)\n",
    "svm_class_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6430147058823529"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "# Model Fitting on Training\n",
    "knn_model.fit(x_train, y_train)\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(knn_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(knn_model.predict_proba(x_test))\n",
    "\n",
    "knn_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "knn_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "knn_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "knn_class_report = metrics.classification_report(y_test, predicted)\n",
    "knn_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "knn_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "knn_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "knn_cv_scores = cross_val_score(KNeighborsClassifier(n_neighbors=3), x_test, y_test, scoring='accuracy', cv=10)\n",
    "knn_cv_mean = np.mean(knn_cv_scores)\n",
    "knn_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(10, 10, 1))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Model\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(10,10,1))\n",
    "# Model Fitting on Training\n",
    "mlp_model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Model for GridSearchCV\n",
    "mlp_model = MLPClassifier(max_iter=5000)\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(10,10,50,1), (10,5,1), (10,10,1)],\n",
    "    'activation': ['logistic', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05,  0.01, 0.001, 0.005, 0.0005],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mlp_cv = GridSearchCV(mlp_model, parameter_space, n_jobs=-1, cv=10, scoring = 'accuracy')\n",
    "mlp_cv.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.DataFrame(mlp_cv.cv_results_).sort_values('mean_test_score', ascending = False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6536764705882353"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using best model parameters to model\n",
    "\n",
    "# Initiate Model\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(10,10,50, 1), activation = 'logistic', solver = 'sgd', alpha = 0.0001, \n",
    "                          learning_rate = 'constant')\n",
    "# Model Fitting on Training\n",
    "mlp_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(mlp_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(mlp_model.predict_proba(x_test))\n",
    "\n",
    "mlp_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "mlp_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "mlp_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "mlp_class_report = metrics.classification_report(y_test, predicted)\n",
    "mlp_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "mlp_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "mlp_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "mlp_cv_scores = cross_val_score(mlp_model, x_test, y_test, scoring='accuracy', cv=10)\n",
    "mlp_cv_mean = np.mean(mlp_cv_scores)\n",
    "mlp_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>cv_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817518</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817518</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d.Tree</td>\n",
       "      <td>0.709877</td>\n",
       "      <td>0.704403</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826568</td>\n",
       "      <td>0.672426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817518</td>\n",
       "      <td>0.653676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.769874</td>\n",
       "      <td>0.643015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r.f.</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.705479</td>\n",
       "      <td>0.919643</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.634926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy  Precision    recall        F1  cv_accuracy\n",
       "0  Logistic  0.691358   0.691358  1.000000  0.817518     0.691176\n",
       "3       SVM  0.691358   0.691358  1.000000  0.817518     0.691176\n",
       "1    d.Tree  0.709877   0.704403  1.000000  0.826568     0.672426\n",
       "5       MLP  0.691358   0.691358  1.000000  0.817518     0.653676\n",
       "4       kNN  0.660494   0.724409  0.821429  0.769874     0.643015\n",
       "2      r.f.  0.679012   0.705479  0.919643  0.798450     0.634926"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model comparison\n",
    "models = pd.DataFrame({\n",
    "  'Model': ['Logistic', 'd.Tree', 'r.f.', 'SVM', 'kNN',  'MLP'],\n",
    "  'Accuracy' : [logistic_acc, dtree_acc, rf_acc, svm_class_acc, knn_acc, mlp_acc],\n",
    "  'Precision': [logistic_precision_score, dtree_precision_score, rf_precision_score, svm_class_precision_score, knn_precision_score, mlp_precision_score],\n",
    "  'recall' : [logistic_recall_score, dtree_recall_score, rf_recall_score, svm_class_recall_score, knn_recall_score, mlp_recall_score],\n",
    "  'F1' : [logistic_f1_score, dtree_f1_score, rf_f1_score, svm_class_f1_score, knn_f1_score, mlp_f1_score],\n",
    "  'cv_accuracy' : [logistic_cv_mean, dtree_cv_mean, rf_cv_mean, svm_class_cv_mean, knn_cv_mean, mlp_cv_mean]\n",
    "})\n",
    "# Print table and sort by test precision\n",
    "models.sort_values(by='cv_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movies with both Numerican and Categorical Features (movies_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract top 10 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Specs      Score\n",
      "4                       inflated_budget  11.378469\n",
      "1                                source   6.771801\n",
      "19       total_post_comments_c_facebook   5.246370\n",
      "25     total_post_haha_count_c_facebook   4.723727\n",
      "10               talking_about_facebook   4.503240\n",
      "12             engagement_rate_facebook   4.497621\n",
      "69               hashtag_volume_twitter   4.480371\n",
      "88  avg_interactions_per_post_instagram   4.028047\n",
      "26       total_post_haha_count_facebook   3.939283\n",
      "2                             franchise   3.861086\n"
     ]
    }
   ],
   "source": [
    "# Extracting using ANOVA F-values\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "X = movies_test.iloc[:,0:89]  #feature columns\n",
    "y = movies_test.iloc[:,-1]    #label columns\n",
    "\n",
    "#Use SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.57112305e-02 1.81424761e-02 1.08149912e-02 2.23792407e-02\n",
      " 4.75217338e-02 1.77326844e-02 2.20002628e-02 1.46897185e-02\n",
      " 1.24854001e-02 9.55014857e-03 1.33231158e-02 1.34275461e-02\n",
      " 1.83899336e-02 1.43050089e-02 1.84816590e-02 1.30088430e-02\n",
      " 1.28314409e-02 1.08498146e-02 1.01737259e-02 1.24354454e-02\n",
      " 1.06222158e-02 8.74134671e-03 7.66636677e-03 1.21653556e-02\n",
      " 1.02173886e-02 1.07126179e-02 9.17585119e-03 1.04151176e-02\n",
      " 8.26903525e-03 8.75427110e-03 7.69914966e-03 4.36358276e-03\n",
      " 3.83136168e-03 1.18823404e-02 1.13446524e-02 1.29997956e-02\n",
      " 1.17039926e-02 1.17841122e-02 1.04228841e-02 1.31887478e-02\n",
      " 1.23741550e-02 1.02397975e-02 1.09981144e-02 1.58187440e-02\n",
      " 1.54508800e-02 1.49477736e-02 1.23182153e-02 1.23698308e-02\n",
      " 1.92681341e-02 1.10940451e-02 1.13707671e-02 1.01897989e-02\n",
      " 9.88947048e-03 8.90084531e-03 6.68618393e-03 1.09442611e-02\n",
      " 1.36490321e-02 1.21052386e-02 9.77289071e-03 8.67539270e-03\n",
      " 7.86522461e-03 8.50121324e-03 8.34663978e-03 6.10894985e-03\n",
      " 6.02101037e-03 7.67089832e-03 9.66612149e-03 1.26225019e-02\n",
      " 9.73831687e-03 1.63387581e-02 4.46441270e-05 0.00000000e+00\n",
      " 1.15405901e-02 8.12364447e-03 6.93672952e-03 9.81112109e-03\n",
      " 9.62521630e-03 9.15261798e-03 7.80911639e-03 7.69093769e-03\n",
      " 8.80414769e-03 7.75361321e-03 7.91054793e-03 8.78066841e-03\n",
      " 7.62085153e-03 7.35496082e-03 7.73236361e-03 9.52142202e-03\n",
      " 9.62899631e-03]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAD4CAYAAADFLW5aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deZhdVZ3u8e9LGAIEAwgi4FDIIDORFCBDEBAnQIEmdBREEa80DtDATUsUVMAJpG0VESHaGBQaMUyNpCUgMkQEkgoZKgECSqIIXhGVCAQChPf+sVd1DsWpKTWcnPB+nqee2mfttdf67XUCv7PW3qe2bBMRERHNY7VGBxARERF9k+QdERHRZJK8IyIimkySd0RERJNJ8o6IiGgyqzc6gFj1bbTRRm5paWl0GBERTWXmzJlP2N643r4k7xh0LS0ttLW1NTqMiIimIun3Xe3LsnlERESTSfKOiIhoMkneERERTSbJOyIiosnkhrUYdO2PLqZlwpRGhxE9WHTOwY0OISJ6KTPviIiIJpPkHRER0WSSvAFJ60v61CC2f7KkdQax/RZJR/Wh/maSrirboyQdVLNvP0l7DUacERExMJK8K+sDg5a8gZOBQUveQAvQ6+Rt+zHbY8vLUcBBNbv3A/qUvCXl3omIiCGU5F05B9hS0mxJP5L0AQBJ10q6pGwfJ+mrZfvDkqaX+hdLGlbK3y3pLkn3SposaYSkk4DNgFsl3SppmKRJkuZJapd0SldBSdpK0i8lzSltbtlN/GNKPKdImiJp59LGLElfLNtnS/pEmanPk7QmcDYwrhx7GnACcEp5PUbSxpKuljSj/Oxd2jpT0k8k3Qn8pE7sx0tqk9S2bMnivr8jERHRpcyYKhOAHW2PkvRBYAxwPbA5sGmpMwb4qaTtgHHA3rZfkHQhcLSk/wHOAA60/UxJhKfaPlvSqcD+tp+QNBrY3PaOUC3ZdxPX5cA5tq+VNJyuP2xNAMbbPqS0uRZVMv898CKwd805nNBxkO3nS2Jvtf2ZcuzawNO2/728/i/gW7Z/LelNwFRgu9LE9sA+tp/tHJDticBEgLU23drdnGNERPRRkvcrTQNOlrQ9cB+wgaRNgT2Bk4CPAqOBGZIA1gYeB95OlczuLOVrAnfVaf9h4C2SvgtMAW6qF4Sk9aiS/LUAtp/r4zmcBCwsfbyrXHPfwvYCSS19aOtAYPtyTgCvkTSibF9fL3FHRMTgSvLuxPajZTb8XuAOYEPgn6lmo0+pymKX2v5c7XGS3g/cbPtDPbT/d0m7AO+hmgX/M3DcAJ/GDKCV6oPCzcBGwCeAmSvQ1mrA2zt/eCjJ/Jn+hRkRESsi17wrTwHr1by+m+omszuoZrHjy2+AW4Cxkl4HIGlDSW8ux+wtaatSvq6kbTq3L2kjYDXbV1Mts+9aLyDbTwF/lHRYOW6tbu5Yf1n8tp8HHgGOpJr9d5zDHb04986vbwJO7HghaVQXMURExBBJ8gZs/5VquXuepPOokt3qtn8L3Es1+55W6t5HlXRvkjSXama7qe2/AMcCV5Tyu4BtSxcTgRsl3Up1Hf02SbOBy4CXzeA7OQY4qbT3G+D1XdSbCywrN7Z13AA3DXi8LGtPA97A8g8gtW6lWhafLWkc8HPg8I4b1qiW31slzZV0HzXXzCMiojFk516iGFytra3O87wjIvpG0kzbrfX2ZeYdERHRZHLD2kpA0vdY/nWuDt+x/aNO9Xbild+pXmp7j8GMLyIiVi5J3isB25/uZb12qr+IFhERr2JZNo+IiGgySd4RERFNJsk7IiKiySR5R0RENJkk74iIiCaT5B0REdFkkrwjIiKaTL7nHYOu/dHFtEyY0ugwoo8WnXNwo0OIiC5k5h0REdFkkrwjIiKazJAmb0ktkub1s41jJV3Qxb7P96ftgSBpkqSxDej3WEmb9aH+2ZIOLNsn1z4rfGUYx4iI6NqqNvN+NSedY4FeJ2/bX7T9y/LyZGCdmt19HkdJw/p6TERErJhGJO9hkn4gab6kmyStLekTkmZImiPp6o5ZoKQjJc0r5XfUtLGZpBslPSTpG6XuOcDakmZLuryUXSdpZunr+I6DJX1c0oOSppdYuprJj5T0e0mrldfrSnpE0hqSRkm6W9JcSddK2qDO8YskbVS2WyXdVrbPlHSppGml/X+S9A1J7eW81ij1Rku6vZzDVEmbdhHnWKAVuLyc/xhJ15R9h0p6VtKakoZLeriUT5I0VtJJVEn/Vkm3djGOHy5jNVvSxR2JWtLTkr4paQ6wZ6eYjpfUJqlt2ZLFXf5jiIiIvmtE8t4a+J7tHYAngSOAa2zvZnsX4H7g46XuF4H3lPIP1LQxChgH7ASMk/RG2xOAZ22Psn10qXec7dFUie0kSa8tS8tfAN5O9RjObbsK1PZiYDbwjlJ0CDDV9gvAj4HTbO8MtANf6uM4bAkcUM7rMuBW2zsBzwIHlwT+XWBsOYdLgK92EedVQBtwtO1RwF0sf/rYGGAesBuwB3BPp2PPBx4D9re9f+dxlLQd1VjvXdpeBnSM77rAPbZ3sf3rTu1OtN1qu3XYOiP7ODQREdGdRnxVbKHt2WV7JtAC7CjpK8D6wAhgatl/JzBJ0s+Aa2rauKUkViTdB7wZeKROXydJOrxsv5Hqg8Prgdtt/60cPxnYppt4r6RKXrcCHwQulDQSWN/27aXOpcDkXpx7rV/YfkFSOzAMuLGUt1ONyVuBHYGbJVHq/Kk3Ddt+UdLvSuLdHfgPYN/SxrQ+xvlOYDQwo8SxNvB42bcMuLqP7UVERD81InkvrdleRpUMJgGH2Z4j6VhgPwDbJ0jaAzgYmClpdBdtvOI8JO0HHAjsaXtJWbIevgLxXg98TdKGVEnsV1QfMHrjRZavbnTueymA7ZckvWDbpfwlqvMRMN/2nqyYO4D3AS8Av6Qa42HAv/WxHQGX2v5cnX3P2V62gvFFRMQKWlluWFsP+FNZKu5YkkXSlrbvsf1F4C9Us+fuvNBxvRgYCfy9JO5tqZbJAWYA75C0gaTVqZbtu2T76XLMd4AbbC8rs/6/SxpTqh0D3F7n8EVUCZ+e+qljAbCxpD0BynX2Hbqp/xTVOHaYRnUj2l22/wK8lmo2X+9u/87H1o7jLcBYSa8rcWwo6c19PJeIiBhAK8tfWPsC1bXYv5TfHYnkPElbU83+bgHmsPxabj0TgbmS7gWOA06QdD9VIrwbwPajkr4GTAf+BjwA9HRH1ZVUy+L71ZR9FLio3Fz3MPCxOsedBfynpC8Dt/XQx8vYfr7ciHZ+WaZfHfg2ML+LQyaVeJ6lunnsHmATqhk4wFzg9TUz/FoTgRslPWZ7f2rGsVz3PgO4qdy49wLwaeD3vT2XnTYfSVv+WldExIBR/f+Xr9okjbD9dJl5XwtcYvvaRse1qmptbXVbW1ujw4iIaCqSZtpurbdvZVk2H2pnSppNtYS8ELiuwfFERET02sqybD6kbI/vXCbpdODITsWTbdf9elajSPoe1Vfcan3H9o8aEU9ERAy9V2Xyrqck6ZUqUddj+9ONjiEiIhrr1bpsHhER0bSSvCMiIppMkndERESTSfKOiIhoMkneERERTSbJOyIiosnkq2Ix6NofXUzLhCmNDiMGwaL82duIhsjMOyIioskkeUdERDSZpkjeklok1XuUZW+O3U/SXjWvT5D0kYGLbtUhaVJ5klnn8lZJ5zcipoiIeKWGXvOWNMz2skHuZj/gaeA3ALYvGuT+Vjm224A8FiwiYiUxaDPvMlt+QNLlku6XdJWkdSQtknRueeb2kZJGSbpb0lxJ10raoBw/WtIcSXOonh/d0e6xki6oeX2DpP3K9nsl3VuOu0VSC3ACcIqk2ZLGSDpT0vhSv6u+bysxTpf0oKQx3ZznMEn/LmleaefEUv5OSbMktUu6RNJapXyRpK+XeNok7SppqqTfSTqh1NlP0h2SpkhaIOmi8ixtJH2/HDdf0lk1cSySdFY5/3ZJ20paTdJDkjYudVaT9NuO1104sLT/oKRDauK5oWyfWc7nNkkPSzqpN/8eIiJi4Az2svlbgQttbwf8A/hUKf+r7V1t/xT4MXCa7Z2BduBLpc6PgBNt79KbjkpC+gFwRDnmSNuLgIuAb9keZXtap8O66htgddu7Ayd3Ku/seKAFGFXauVzScGASMM72TlQrHJ+sOeYPtkcB00q9scDbgbNq6uwOnAhsD2wJ/FMpP70833Vn4B2Sdq455gnbuwLfB8bbfgm4DDi67D8QmGP7L92cT0vp+2DgonIunW0LvKfU+5KkNTpXkHR8+RDQtmzJ4m66i4iIvhrs5P2I7TvL9mXAPmX7SgBJI4H1bd9eyi8F9pW0fim/o5T/pBd9vR24w/ZCANt/665yV33XVLmm/J5JldC6ciBwse0Xa/p9K7DQ9oNdtH19+d0O3GP7qZJQl5ZzB5hu++FyWeEKlo/dP5dVi1nADlTJvbuYLwE6rvEfR/WhqDs/s/2S7YeAh6kSdWdTbC+1/QTwOLBJ5wq2J9putd06bJ2RPXQZERF9MdjJ2128fqYfbb7Iy+OuNzMcCEvL72UM/L0BHW2/VLPd8bqjr1eMnaQtgPHAO8ssfwovP/9XxGz7EeDPkg6gmin/oofYunrP6sX/sr4iImJoDHbyfpOkPcv2UcCva3faXgz8veaa8jHA7bafBJ6U1DHbPLrmsEXAqHL99o1UCQngbqpZ+xYAkjYs5U8B63UOrKu+V+Acbwb+RdLqNf0uAFokbdWPtneXtEW51j2OauxeQ/XBZ7GkTYD39bKtH1KtfEzuxQ2CR5ax3RJ4SzmXiIhYiQx28l4AfFrS/cAGVNdiO/socJ6kucAo4OxS/jHge5JmA6qpfyewELgPOB+4F6AsOx8PXFNucruy1P85cHjHDWu97Lsvfgj8AZhb+j3K9nMl/smS2qlm1H29y30GcAFwP9X5Xmt7DtVy+QPAf1GNRW9cD4yg5yVzqM5lOtUM/YRyLhERsRKRXW9VdAAaru70vsH2joPSwSqs3D0/3vYhA9ReK9VNe13eNT+YWltb3daWb5pFRPSFpJnlBuVXyLXKVZykCVR3uh/dU92IiGgOgzbzXtVIeg9wbqfihbYPb0Q8/SHpdODITsWTbX91MPrLzDsiou8y8x4AtqcCUxsdx0AoSXpQEnVERAy+pvjb5hEREbFckndERESTSfKOiIhoMkneERERTSbJOyIioskkeUdERDSZJO+IiIgmk+95x6Brf3QxLROmNDqMGGSLzjm40SFEvGpk5h0REdFkkrwjIiKaTJJ31NXxfPKIiFj5JHmvIiStK2mKpDmS5kkaJ+mdkmZJapd0iaS1St1FkjYq262SbivbZ0r6iaQ7gZ9IGibp30t7cyWdWOqNlnS7pJmSpkratFHnHRHxapTZ1arjvcBjtg8GkDQSmAe80/aDkn5M9WjQb/fQzvbAPraflfRJoAUYZftFSRtKWgP4LnCo7b9IGkf1kJPjahuRdDxwPMCw12w8YCcZERGZea9K2oF3STpX0hiqpLvQ9oNl/6XAvr1o53rbz5btA4GLbb8IYPtvwFuBHYGbJc0GzgDe0LkR2xNtt9puHbbOyP6cV0REdJKZ9yqizK53BQ4CvgL8qpvqL7L8g9vwTvue6aErAfNt77lCgUZERL9l5r2KkLQZsMT2ZcB5wJ5Ai6StSpVjgNvL9iJgdNk+optmbwb+pePmNUkbAguAjSXtWcrWkLTDQJ5LRER0L8l71bETML0sZX+Jajn7Y8BkSe3AS8BFpe5ZwHcktQHLumnzh8AfgLmS5gBH2X4eGAucW8pmA3sNxglFRER9st3oGGIVt9amW3vTj/Z0n1w0u/yFtYiBJWmm7dZ6+3LNOwbdTpuPpC3/Y4+IGDBZNo+IiGgySd4RERFNJsk7IiKiySR5R0RENJkk74iIiCaT5B0REdFkkrwjIiKaTJJ3REREk0nyjoiIaDJJ3hEREU0mfx41Bl37o4tpmTCl0WHEEMnfOI8YfJl5R0RENJkk74iIiCaT5F1D0n6SBuTZ1JJGSTqoH8dfIWmupFMGIp7S5tMD1M5tkuo+pi4iIgZfrnm/3H7A08BvelNZ0uq2X+xi9yigFfifvgYh6fXAbra36uuxERGx6uvVzFvShyVNlzRb0sWShkl6WtJXJc2RdLekTUrdLcvrdklf6ZjtSRoh6RZJ95Z9h9a0/wVJCyT9usw4x9e0daOkmZKmSdq2lE+S9P3Sz8NlxnyJpPslTapp992S7ip9TpY0opQvknRWTSzbSmoBTgBOKec5pouxmCTpIkn3AN+QtHvpY5ak30h6q6Q1gbOBcaWtcZLWLTFOL3UPrdd+cROweUcckj4haUYZ66slrVNi2UTStaV8TseqQb33qyb+b0maX96LjUvZqDKWc0t7G3RXXtPWamU8vlJnnI6X1CapbdmSxd2cakRE9FWPyVvSdsA4YG/bo4BlwNHAusDdtncB7gA+UQ75DvAd2zsBf6xp6jngcNu7AvsD31RlN+AIYBfgfVSz1Q4TgRNtjwbGAxfW7NsA2BM4Bbge+BawA7BTSTobAWcAB5Y+24BTa45/opR/HxhvexFwEfAt26NsT+tmWN4A7GX7VOABYIzttwFfBL5m+/myfWVp60rgdOBXtncv53+epHW7aP8DwO9q4rjG9m5lrO8HPl7qnQ/cXsp3BeZ3835B9Z612d4BuB34Uin/MXCa7Z2B9l6UQ7VqcznwkO0zOp+A7Ym2W223DltnZDdDGRERfdWbZfN3AqOBGZIA1gYeB54Hbih1ZgLvKtt7AoeV7f8C/r1sC/iapH2Bl4DNgU2AvYH/tv0c8Jykn0M1Uwf2AiaXfgHWqonr57YtqR34s+32ctx8oIUqwW4P3FmOXxO4q+b4a2pi/6dejEOtybaXle2RwKWStgYMrNHFMe8GPtCxqgAMB95ElYx7smOZ3a4PjACmlvIDgI8AlHgWSzqG+u8XVON+Zdm+DLhG0khgfdu3l/JLqca8bnlNTBcDP7P91V7EHxERA6g3yVvApbY/97JCabxtl5fLetHW0cDGwGjbL0haRJXAurIa8GSZPdaztPx+qWa74/XqJaabbX+oh+N7E3tnz9Rsfxm41fbhZen9ti6OEXCE7QV97AtgEnCY7TmSjqW6Nt+Vuu9XF9xzlS79Bthf0jfLB6+IiBgivbnmfQswVtLrACRtKOnN3dS/m2oZHOCDNeUjgcdL4t4f6GjjTuD9koaX2fYhALb/ASyUdGTpV5J26e2JlTj2lrRVOX5dSdv0cMxTwHp96AOq83q0bB/bTVtTgRNVpsOS3taHPtYD/iRpDZYvgUP13nyytDeszJa7e79WA8aW7aOAX9teDPy95hr/MVRL8XXLa/r+T6qb8X4mKTc+RkQMoR6Tt+37qK4d3yRpLnAzsGk3h5wMnFrqbgV03K10OdBalrk/QnWtGNszqK5ZzwV+QXVtteOYo4GPS5oDzAe6u8mrc9x/oUqmV5RY7gK27eGwnwOHd3fDWh3fAL4uaRYvn8HfCmzfccMa1Qx9DWBuWdr/cm/PBfgCcA/VB50Hasr/lWr22061/L99D+/XM8DukuZRLbmfXco/SnUNfi7VXfI9lQNg+z+AWcBPJOVrhxERQ0TLV74HqMHqTuhny/XoDwIfst1t0pU0wvbT5dg7gONt3zuggUXDtLa2uq2trdFhREQ0FUkzbdf9mxqDsdw5GrigLA8/CRzXi2MmStqe6hr4pUncERERXRvw5F2+2tSXa9PYPmqg4+gvSacDR3YqnjyQd1dLeg9wbqfihbYPH6g+IiJi1ZMbjbpQkvSgfg3K9lSWf+0rIiKiV3KTUURERJNJ8o6IiGgySd4RERFNJsk7IiKiySR5R0RENJkk74iIiCaT5B0REdFk8j3vGHTtjy6mZcKURocRQ2TROQc3OoSIVV5m3hEREU0myTsiIqLJNHXylrS+pE/1UKdFUo9/O73Umzdw0XXZz8nl6Wnd1TlS0v2Sbh3AfidJGttzzR7bOVbSBQMRU0RErJimTt7A+kC3yRtoAVamB5+cDHSbvIGPA5+wvf8QxBMREU2m2ZP3OcCWkmZLOq/8zJPULmlcTZ0xpc4pZYY9TdK95Wev3nRUZpz/Lek2SQ9J+lLNvlNLv/MknVzK1pU0RdKcUj5O0knAZsCtXc2qJX0R2Af4z3I+XcYr6bRyrnMknVPKtpR0o6SZ5bhta5o/UFKbpAclHVLqD5f0o9LOLEn7d1feKdaDJd0laaM6+44vfbUtW7K4N0McERG91Ox3m08AdrQ9StIRwAlUjyPdCJgh6Y5SZ7ztjmS1DvAu289J2hq4Aqj7sPM6dgd2BJaU9qcABj4G7AEIuEfS7cBbgMdsH1z6HWl7saRTgf1tP1GvA9tnSzqgxNzWVbyS3gccCuxhe4mkDUsTE4ETbD8kaQ/gQuCAsq+lnMOWVB8gtgI+XXXrnUqiv0nSNt2UU87ncOBU4CDbf69zHhNLLKy16dbu5fhGREQvNHvyrrUPcIXtZcCfSwLdDfhHp3prABdIGgUsA7ah9262/VcASdeUPg1ca/uZmvIxwI3ANyWdC9xQnnO+IrqK90DgR7aXANj+m6QRwF7AZEkdx69V09bPbL8EPCTpYWDbcg7fLW08IOn3pY+uyqH6MNAKvNt25/GNiIhBtiol7946Bfgz1Qx9NeC5PhzbeQbZ5YzS9oOSdgUOAr4i6RbbZ/c1WPoW72rAk7ZHdRVWD69763dUKwvbAG0r2EZERKygZr/m/RSwXtmeBoyTNEzSxsC+wPROdQBGAn8qM9BjgGF96O9dkjaUtDZwGHBn6fcwSetIWhc4HJgmaTNgie3LgPOAXevE3BtdxXsz8LGOO9clbVhmwQslHVnKJGmXmraOlLSapC2pku+CEv/Rpf42wJt6KAf4PXAE8GNJO/ThXCIiYgA09czb9l8l3anqK16/AOYCc6hmlJ+1/f8k/RVYJmkOMInqGvDVkj5CtbT9TB+6nA5cDbwBuMx2G1Rfwyr7AH5oe5ak9wDnSXoJeAH4ZNk/EbhR0mO9vJu8bry2byxL6W2Sngf+B/g8VcL9vqQzqJbcf1rGBOAPJc7XUF0Xf07ShaV+O/AicKztpd2UU/p/QNLRVEv077f9u65OYKfNR9KWv7oVETFgZOdeot6QdCzQavszjY6l2bS2trqtLavrERF9IWmm7bo3VDf7snlERMSrTlMvmw+Gstx9bqfihbYPp1p2H8i+7uHld4MDHGO7fSD7iYiIVUuSdye2pwJTh6ivPYain4iIWLVk2TwiIqLJJHlHREQ0mSTviIiIJpPkHRER0WSSvCMiIppMkndERESTyVfFYtC1P7qYlglTGh1GNNii/InciAGTmXdERESTSfKOiIhoMitN8pa0vqRP9VCnRdJRvWirpTxpbEh1jk9Sq6Tzh6DfkzseDdrL+j+UtH3Z/nxNeY/vQURENN5Kk7yB9YGeEkcL0GPybqAWauKz3Wb7pCHo92Sg18nb9v+xfV95+fmaXb15D16mPDN8Zfp3FBGxyluZ/qd7DrClpNmSzis/8yS1SxpXU2dMqXNKmelOk3Rv+dmrNx1JOlbSdZJulrRI0mcknSpplqS7JW1Y6m0p6UZJM0s/25bySZLOl/QbSQ9LGttFfPtJuqEcs2Hpc27pY+dSfqakSyTdVto6qZSvK2mKpDllHMa98kyg1N8MuFXSrZKOlPQfZd+/Snq4bL9F0p1l+7ayKnAOsHaJ9/LO70Gp+2+SZpS4zyplLZIWSPoxMA94Y+/e4oiIGAgr093mE4AdbY+SdARwArALsBEwQ9Idpc5424cAlKXid9l+TtLWwBVA3Wef1rEj8DZgOPBb4DTbb5P0LeAjwLeBicAJth+StAdwIXBAOX5TYB9gW+B64Ko68e1X099ZwCzbh0k6APgxMKrs2xbYH1gPWCDp+8B7gcdsH1zaGlnvJGyfL+lUYH/bT0h6PfDZsnsM8FdJm5ftOzodO0HSZ2yPKn20UN6D8vrdwNbA7oCA6yXtC/yhlH/U9t314pJ0PHA8wLDXbFyvSkRErKCVKXnX2ge4wvYy4M+Sbgd2A/7Rqd4awAWSRgHLgG360Mettp8CnpK0GPh5KW8HdpY0AtgLmCyp45jax3deZ/sl4D5Jm/TynI4AsP0rSa+V9Jqyb4rtpcBSSY8Dm5Q4vinpXOAG29N6c1K2/5+kEZLWo5oR/xewL1XyvqY3bdR4d/mZVV6PoErafwB+31XiLnFMpPrww1qbbu0+9hsREd1YWZN3b50C/Jlqhr4a8Fwfjl1as/1SzeuXqMZlNeDJjlloD8erizorEssyYHXbD0raFTgI+IqkW2yf3cv2fgN8DFgATAOOA/YE/m8f4xLwddsXv6ywmqE/08e2IiJigKxM17yfolo2hirhjJM0TNLGVDPH6Z3qAIwE/lRmwMcAwwYqGNv/ABZKOhL+98asXfpwDp1NA44ube0HPFH6qEvSZsAS25cB5wG79qHfacB4qmXyWVRL8kttL65z7AuS1uiinanAcWUVAkmbS3pdN3FERMQQWGlm3rb/KulOVV/x+gUwF5gDGPhsWQ7+K7BM0hxgEtU16KslfQS4kYGfDR4NfF/SGVRL9D8tMXVlbqf4ZtXsOxO4RNJcYAnw0R763gk4T9JLwAvAJ7upOxG4UdJjtvenSt5vBO6wvUzSI8AD3Rw7V9K9to+ufQ9s/5uk7YC7yqWDp4EPU60OREREg8jO5cgYXK2trW5ra2t0GBERTUXSTNt1b8JemZbNIyIiohdWmmXzwSDpPcC5nYoX2j68EfH0l6RrgS06FZ9me2oj4omIiMZYpZN3SWqrTGJr1g8dERExsLJsHhER0WSSvCMiIppMkndERESTSfKOiIhoMkneERERTSbJOyIioskkeUdERDSZVfp73rFyaH90MS0TpjQ6jFhFLDrn4EaHENFwmXlHREQ0mSTviIiIJpPkvQIk3Sap7pNeVtF+P1+z3VIeGRoREQ2S5N0FVTI+lc/3XCUiIoZKklONMqtcIOnHwDzgGEl3SbpX0mRJI+oc8+56dSR9UdIMSfMkTZSkUn6SpPskzZX001K2rqRLJE2XNItjl/MAAA1lSURBVEvSoaV8bUk/lXR/eaLY2j3E/7Sk8yTNl/RLSbuX2frDkj5Q6gyX9CNJ7aWv/Uv5sZKukXSjpIckfaOUnwOsLWm2pMtLV8Mk/aD0c5OkV8Ql6XhJbZLali1ZvELvR0RE1Jfk/UpbAxcC7wA+Dhxoe1egDTi1tqKkjYAzuqhzge3dbO9IlXQPKeUTgLfZ3hk4oZSdDvzK9u7A/sB5ktYFPgkssb0d8CVgdA+xr1va2QF4CvgK8C7gcODsUufTgG3vBHwIuFTS8LJvFDAO2AkYJ+mNticAz9oeZfvomjH6XunnSeCIzoHYnmi71XbrsHVG9hB2RET0Rb4q9kq/t323pEOA7YE7y6R5TeCuTnXf3k2d/SV9FlgH2BCYD/wcmAtcLuk64LpS993ABySNL6+HA28C9gXOB7A9V9LcHmJ/HrixbLcDS22/IKkdaCnl+wDfLW0+IOn3wDZl3y22FwNIug94M/BInX4W2p5dtmfWtB0REUMgyfuVnim/Bdxs+0Pd1K1bp8xkLwRabT8i6UyqhAxwMFVSfj9wuqSdSjtH2F7QqZ2+xv6CbZftl4ClALZfktSb93ppzfYyuv730blet8v5ERExsLJs3rW7gb0lbQX/e116m17W6UjUT5Rr4GPL/tWAN9q+FTgNGAmMAKYCJ9ZcF39bOf4O4KhStiOw8wCc1zTg6NLmNlQz/AXdHgEvSFpjAPqOiIgBkOTdBdt/AY4FrijL1XcB2/amju0ngR9Q3fQ2FZhRDhkGXFaWsWcB55e6XwbWAOZKml9eA3wfGCHpfqpr1jMH4NQuBFYrMVwJHGt7aQ/HTCyxXd5DvYiIGAJavsoaMThaW1vd1tbW6DAiIpqKpJm26/5tj8y8IyIimkxuWGtCku4B1upUfIzt9kbEExERQyvJuwnZ3qPRMURERONk2TwiIqLJJHlHREQ0mSTviIiIJpPkHRER0WSSvCMiIppMkndERESTSfKOiIhoMvmedwy69kcX0zJhSqPDiFXMonMObnQIEQ2TmXdERESTSfKOiIhoMknescIktUia1+g4IiJebZK8h5ikQbnPYLDajYiIlU+Sdw8kfUHSAkm/lnSFpPGStpR0o6SZkqZJ2rbUnSTpfEm/kfSwpLGlfL9S73rgvlL2YUnTJc2WdLGkYd3E8HFJD5b6P5B0QU1/F5WnjH1D0oaSrpM0V9LdknYu9c6UNL6mvXll1twi6QFJl0u6X9JVktYpdUZLur2c41RJm9aUz5E0B/h0NzEfL6lNUtuyJYv7+S5EREStJO9uSNoNOALYBXgf0PFQ9InAibZHA+OBC2sO2xTYBzgEOKemfFfgX21vI2k7YBywt+1RwDLg6C5i2Az4AvB2YG9g205V3gDsZftU4Cxglu2dgc8DP+7Fab4VuND2dsA/gE9JWgP4LjC2nOMlwFdL/R+Vc9+lu0ZtT7Tdart12DojexFGRET0VpZau7c38N+2nwOek/RzYDiwFzBZUke92mdrX2f7JeA+SZvUlE+3vbBsvxMYDcwobawNPN5FDLsDt9v+G4CkycA2Nfsn215Wtveh+rCB7V9Jeq2k1/Rwjo/YvrNsXwacBNwI7AjcXOIbBvxJ0vrA+rbvKPV/QvWhJiIihlCSd9+tBjxZZsz1LK3ZVs32M53KL7X9uQGI55meq/AiL19lGV6z7U51TRXffNt71u4oyTsiIhosy+bduxN4v6ThkkZQLYUvARZKOhJAlW6XkOu4BRgr6XWljQ0lvbmLujOAd0jaoNyUdkQ37U6jLL9L2g94wvY/gEVUy/ZI2hXYouaYN0nqSNJHAb8GFgAbd5RLWkPSDrafBJ6UtE+pX3epPyIiBleSdzdszwCuB+YCvwDagcVUSevj5aat+cChfWz3PuAM4CZJc4Gbqa6V16v7KPA1YDrVh4lFJYZ6zgRGlzbPAT5ayq8GNpQ0H/gM8GDNMQuAT0u6H9gA+L7t54GxwLnlHGdTXSoA+BjwPUmzefnKQkREDBHZnVdNo5akEbafLndh3wEcb/veBsWwOnAtcIntaweg3RbgBts79ret7rS2trqtrW0wu4iIWOVImmm7td6+XPPu2URJ21NdJ750qBN3caakA0sMNwHXNSCGiIhYSSR598D2UUPVV/m+9lqdio+xPb5e/f6yvYjqrvKIiGgiSd4rEdt7NDqGiIhY+eWGtYiIiCaT5B0REdFkkrwjIiKaTJJ3REREk0nyjoiIaDJJ3hEREU0mXxWLQdf+6GJaJkxpdBgREUNq0TkHD1rbmXlHREQ0mSTviIiIJpPkHRER0WSSvOuQ9Jte1Bkjab6k2ZK2kzSvh/otkvr8d9IlTZI0tpv9iyRt1Nd2e9t+D8eOknTQivYdERErJsm7Dtt79VyLo4Gv2x4FPNuL+i3AkD3kZIiMApK8IyKGWJJ3HZKeLr/3k3SbpKskPSDpclX+D/DPwJclXd7p2BZJ0yTdW346PgicA4wpM/VTJA2TdJ6kGZLmSvqXcrwkXSBpgaRfAq/rRcifldQuabqkrUo7L5tR15xTl+1LOqic50xJ50u6oZSvK+mS0v4sSYdKWhM4GxhXzmlcp3E4XlKbpLZlSxb3YfQjIqIn+apYz94G7AA8BtwJ7G37h5L2AW6wfZWklpr6jwPvsv2cpK2BK4BWYAIw3vYhUCU3YLHt3SStBdwp6abS31uB7YFNgPuAS3qIcbHtnSR9BPg2cEg3dQ+v176k4cDFwL62F0q6ouaY04Ff2T5O0vrAdOCXwBeBVtuf6dyJ7YnARIC1Nt3aPcQfERF9kJl3z6bb/qPtl4DZVMvf3VkD+IGkdmAyVZKs593ARyTNBu4BXgtsDewLXGF7me3HgF/1IsYran7v2UPdrtrfFnjY9sJObXbEOqHEehswHHhTL+KKiIhBkJl3z5bWbC+j5zE7BfgzsAvVh6Pnuqgn4ETbU19WuGI3gLnO9oulfyStBqy5Au3+b1jAEbYXvKxQyvPHIyIaIDPvgTcS+FOZqR8DDCvlTwHr1dSbCnxS0hoAkraRtC5wB9V15GGSNgX270Wf42p+31W2FwGjy/YHqFYE6Kb9BcBbai4B1F7DngqcKEkl1rd1cU4RETEEMvMeeBcCV5frzzcCz5TyucAySXOAScB3qJbg7y1J8S/AYcC1wAFU16L/wPJk3J0NJM2lWiX4UCn7AfDfpb/aOOq2b/tZSZ8CbpT0DDCjpv0vU11Ln1tm8QuprqvfyvLl9K/bvrJecDttPpK2QfwzgRERrzaycy9RVCSNsP10+TDxPeAh29/qb7utra1ua2vrf4AREa8ikmbabq23L8vmUesTZRY9n2r5/+IGxxMREXVk2bxJSLoW2KJT8Wmdb3jrjzLL7vdMOyIiBleSd5OwfXijY4iIiJVDls0jIiKaTG5Yi0En6Smqr6IFbAQ80eggViIZj+UyFstlLCpvtr1xvR1ZNo+hsKCrOyZfbSS1ZSyWy3gsl7FYLmPRsyybR0RENJkk74iIiCaT5B1DYWKjA1iJZCxeLuOxXMZiuYxFD3LDWkRERJPJzDsiIqLJJHlHREQ0mSTv6BdJ75W0QNJvJU2os38tSVeW/ffUPHIUSZ8r5QskvWco4x4MKzoWkl4r6VZJT0u6YKjjHgz9GIt3SZopqb38PmCoYx9o/RiL3SXNLj9zJDX9X1nsz/8vyv43lf9Oxg9VzCst2/nJzwr9UD2r/HfAW4A1gTnA9p3qfAq4qGx/ELiybG9f6q9F9TfbfwcMa/Q5NWgs1gX2AU4ALmj0uTR4LN4GbFa2dwQebfT5NHAs1gFWL9ubAo93vG7Gn/6MRc3+q4DJwPhGn0+jfzLzjv7YHfit7YdtPw/8FDi0U51DgUvL9lXAO8sjRw8Ffmp7qe2FwG9Le81qhcfC9jO2fw08N3ThDqr+jMUs24+V8vnA2pLWGpKoB0d/xmKJ7RdL+XCg2e8u7s//L5B0GLCQ6t/Fq16Sd/TH5sAjNa//WMrq1in/I1oMvLaXxzaT/ozFqmagxuII4F7bSwcpzqHQr7GQtIek+UA7cEJNMm9GKzwWkkYApwFnDUGcTSHJOyJWOpJ2AM4F/qXRsTSS7Xts7wDsBnxO0vBGx9QgZwLfsv10owNZWSR5R388Cryx5vUbSlndOpJWB0YCf+3lsc2kP2OxqunXWEh6A3At8BHbvxv0aAfXgPy7sH0/8DTVfQDNqj9jsQfwDUmLgJOBz0v6zGAHvDJL8o7+mAFsLWkLSWtS3WByfac61wMfLdtjgV+5uvPkeuCD5e7SLYCtgelDFPdg6M9YrGpWeCwkrQ9MASbYvnPIIh48/RmLLUoCQ9KbgW2BRUMT9qBY4bGwPcZ2i+0W4NvA12yvEt/MWGGNvmMuP839AxwEPEh1F+nppexs4ANlezjV3aG/pUrOb6k59vRy3ALgfY0+lwaPxSLgb1Szqz/S6S7cZvtZ0bEAzgCeAWbX/Lyu0efToLE4hurmrNnAvcBhjT6XRo1FpzbOJHeb58+jRkRENJssm0dERDSZJO+IiIgmk+QdERHRZJK8IyIimkySd0RERJNJ8o6IiGgySd4RERFN5v8DpavdDVJFt6YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparing ANOVA with using Feature Importance of Extra Trees Classifier\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing features and trying models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_test_sel = movies_test[['inflated_budget',\n",
    "                               'source',\n",
    "       'total_post_comments_c_facebook',\n",
    "     'total_post_haha_count_c_facebook',\n",
    "                'talking_about_facebook',\n",
    "              'engagement_rate_facebook',\n",
    "               'hashtag_volume_twitter',\n",
    "  'avg_interactions_per_post_instagram',\n",
    "       'total_post_haha_count_facebook',\n",
    "               'franchise',\n",
    "                'successflop']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Models\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import export_graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting Dataset into train and test\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# test_size: what proportion of original data is used for test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "   movies_test_sel.loc[:,movies_test_sel.columns != 'successflop'] ,movies_test_sel[['successflop']], random_state=1234, test_size=0.30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inflated_budget</td>\n",
       "      <td>0.200457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>avg_tweet_interaction_twitter</td>\n",
       "      <td>0.110421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>engagement_rate_facebook</td>\n",
       "      <td>0.108979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>talking_about_facebook</td>\n",
       "      <td>0.107144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_post_comments_c_facebook</td>\n",
       "      <td>0.103709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hashtag_volume_twitter</td>\n",
       "      <td>0.089170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total_mentions_twitter</td>\n",
       "      <td>0.086310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>avg_interactions_per_post_instagram</td>\n",
       "      <td>0.069425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_post_haha_count_facebook</td>\n",
       "      <td>0.062692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_post_haha_count_c_facebook</td>\n",
       "      <td>0.061693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              features  importance\n",
       "0                      inflated_budget    0.200457\n",
       "9        avg_tweet_interaction_twitter    0.110421\n",
       "4             engagement_rate_facebook    0.108979\n",
       "3               talking_about_facebook    0.107144\n",
       "1       total_post_comments_c_facebook    0.103709\n",
       "5               hashtag_volume_twitter    0.089170\n",
       "8               total_mentions_twitter    0.086310\n",
       "6  avg_interactions_per_post_instagram    0.069425\n",
       "7       total_post_haha_count_facebook    0.062692\n",
       "2     total_post_haha_count_c_facebook    0.061693"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Variable importance for Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "pd.DataFrame({'features' : x_train.columns.to_numpy(), 'importance':rf.feature_importances_}).sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "logistic_model = LogisticRegression(random_state = 0)\n",
    "# Model Fitting on Training\n",
    "logistic_model = logistic_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(logistic_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(logistic_model.predict_proba(x_test))\n",
    "\n",
    "logistic_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "logistic_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "logistic_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "logistic_class_report = metrics.classification_report(y_test, predicted)\n",
    "logistic_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "logistic_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "logistic_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "logistic_cv_score = cross_val_score(LogisticRegression(), x_test, y_test, scoring='accuracy', cv=10)\n",
    "logistic_cv_mean = np.mean(logistic_cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24, 26],\n",
       "       [35, 77]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "dtree_model = tree.DecisionTreeClassifier(max_depth=3) \n",
    "\n",
    "# Model Fitting on Training\n",
    "dtree_model = dtree_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(dtree_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(dtree_model.predict_proba(x_test))\n",
    "\n",
    "dtree_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "dtree_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "dtree_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "dtree_class_report = metrics.classification_report(y_test, predicted)\n",
    "dtree_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "dtree_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "dtree_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "dtree_cv_score = cross_val_score(tree.DecisionTreeClassifier(max_depth=3), x_test, y_test, scoring='accuracy', cv=10)\n",
    "dtree_cv_mean = np.mean(dtree_cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "rf_model = RandomForestClassifier() \n",
    "\n",
    "# Model Fitting on Training\n",
    "rf_model = rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(rf_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(rf_model.predict_proba(x_test))\n",
    "\n",
    "rf_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "rf_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "rf_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "rf_class_report = metrics.classification_report(y_test, predicted)\n",
    "rf_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "rf_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "rf_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "rf_cv_scores = cross_val_score(RandomForestClassifier(), x_test, y_test, scoring='accuracy', cv=10)\n",
    "rf_cv_mean = np.mean(rf_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "\n",
    "svm_class_model = SVC(probability=True)\n",
    "\n",
    "# Model Fitting on Training\n",
    "svm_class_model = svm_class_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(svm_class_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(svm_class_model.predict_proba(x_test))\n",
    "\n",
    "svm_class_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "svm_class_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "svm_class_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "svm_class_class_report = metrics.classification_report(y_test, predicted)\n",
    "svm_class_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "svm_class_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "svm_class_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "svm_class_cv_scores = cross_val_score(SVC(probability=True), x_test, y_test, scoring='accuracy', cv=10)\n",
    "svm_class_cv_mean = np.mean(svm_class_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5500757575757577"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Model Fitting on Training\n",
    "knn_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(knn_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(knn_model.predict_proba(x_test))\n",
    "\n",
    "knn_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "knn_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "knn_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "knn_class_report = metrics.classification_report(y_test, predicted)\n",
    "knn_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "knn_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "knn_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "knn_cv_scores = cross_val_score(KNeighborsClassifier(n_neighbors=3), x_test, y_test, scoring='balanced_accuracy', cv=10)\n",
    "knn_cv_mean = np.mean(knn_cv_scores)\n",
    "knn_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7013333333333334"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(10,10, 1))\n",
    "# Fit the model\n",
    "mlp_model.fit(x_train, y_train)\n",
    "# Accuracy\n",
    "mlp_model.score(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4588235294117647"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions/probs on the test dataset\n",
    "predicted = pd.DataFrame(mlp_model.predict(x_test))\n",
    "probs = pd.DataFrame(mlp_model.predict_proba(x_test))\n",
    "\n",
    "mlp_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "mlp_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "mlp_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "mlp_class_report = metrics.classification_report(y_test, predicted)\n",
    "mlp_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "mlp_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "mlp_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "mlp_cv_scores = cross_val_score(mlp_model, x_test, y_test, scoring='accuracy', cv=10)\n",
    "mlp_cv_mean = np.mean(mlp_cv_scores)\n",
    "mlp_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>cv_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817518</td>\n",
       "      <td>0.678676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d.Tree</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.810409</td>\n",
       "      <td>0.653309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r.f.</td>\n",
       "      <td>0.697531</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.803213</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.623457</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.716279</td>\n",
       "      <td>0.611397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>0.771784</td>\n",
       "      <td>0.550076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.689441</td>\n",
       "      <td>0.991071</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.458824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy  Precision    recall        F1  cv_accuracy\n",
       "3       SVM  0.691358   0.691358  1.000000  0.817518     0.678676\n",
       "1    d.Tree  0.685185   0.694268  0.973214  0.810409     0.653309\n",
       "2      r.f.  0.697531   0.729927  0.892857  0.803213     0.647059\n",
       "0  Logistic  0.623457   0.747573  0.687500  0.716279     0.611397\n",
       "4       kNN  0.660494   0.720930  0.830357  0.771784     0.550076\n",
       "5       MLP  0.685185   0.689441  0.991071  0.813187     0.458824"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model comparison\n",
    "models = pd.DataFrame({\n",
    "  'Model': ['Logistic', 'd.Tree', 'r.f.', 'SVM', 'kNN',  'MLP'],\n",
    "  'Accuracy' : [logistic_acc, dtree_acc, rf_acc, svm_class_acc, knn_acc, mlp_acc],\n",
    "  'Precision': [logistic_precision_score, dtree_precision_score, rf_precision_score, svm_class_precision_score, knn_precision_score, mlp_precision_score],\n",
    "  'recall' : [logistic_recall_score, dtree_recall_score, rf_recall_score, svm_class_recall_score, knn_recall_score, mlp_recall_score],\n",
    "  'F1' : [logistic_f1_score, dtree_f1_score, rf_f1_score, svm_class_f1_score, knn_f1_score, mlp_f1_score],\n",
    "  'cv_accuracy' : [logistic_cv_mean, dtree_cv_mean, rf_cv_mean, svm_class_cv_mean, knn_cv_mean, mlp_cv_mean]\n",
    "})\n",
    "# Print table and sort by test precision\n",
    "models.sort_values(by='cv_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_test_normalize = movies_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cols = ['inflated_budget', 'likes_c_facebook', 'likes_facebook',\n",
    "       'talking_about_c_facebook', 'talking_about_facebook',\n",
    "       'engagement_rate_c_facebook', 'engagement_rate_facebook',\n",
    "       'total_post_c_facebook', 'total_post_facebook',\n",
    "       'total_post_likes_c_facebook', 'total_post_likes_facebook',\n",
    "       'total_post_shares_c_facebook', 'total_post_shares_facebook',\n",
    "       'total_post_comments_c_facebook', 'total_post_comments_facebook',\n",
    "       'total_post_love_count_c_facebook', 'total_post_love_count_facebook',\n",
    "       'total_post_wow_count_c_facebook', 'total_post_wow_count_facebook',\n",
    "       'total_post_haha_count_c_facebook', 'total_post_haha_count_facebook',\n",
    "       'total_post_sad_count_c_facebook', 'total_post_sad_count_facebook',\n",
    "       'total_post_angry_count_c_facebook', 'total_post_angry_count_facebook',\n",
    "       'total_post_thankful_count_c_facebook',\n",
    "       'total_post_thankful_count_facebook',\n",
    "       'total_post_tracked_reactions_c_facebook',\n",
    "       'total_post_tracked_reactions_facebook',\n",
    "       'total_post_reactions_count_c_facebook',\n",
    "       'total_post_reactions_count_facebook',\n",
    "       'total_post_interactions_c_facebook',\n",
    "       'total_post_interactions_facebook', 'total_post_video_c_facebook',\n",
    "       'total_post_video_facebook', 'total_post_video_interactions_c_facebook',\n",
    "       'total_post_video_interactions_facebook', 'tweets_c_twitter',\n",
    "       'tweets_twitter', 'followers_c_twitter', 'followers_twitter',\n",
    "       'mentions_twitter', 'total_mentions_twitter',\n",
    "       'total_retweets_c_twitter', 'total_retweets_twitter',\n",
    "       'total_favorites_c_twitter', 'total_favorites_twitter',\n",
    "       'total_replies_c_twitter', 'total_replies_twitter',\n",
    "       'tracked_posts_c_twitter', 'tracked_posts_twitter',\n",
    "       'video_tracked_posts_c_twitter', 'video_tracked_posts_twitter',\n",
    "       'video_retweets_c_twitter', 'video_retweets_twitter',\n",
    "       'video_favorites_c_twitter', 'video_favorites_twitter',\n",
    "       'video_replies_c_twitter', 'video_replies_twitter',\n",
    "       'video_views_c_twitter', 'video_views_twitter',\n",
    "       'total_post_interactions_c_twitter', 'total_post_interactions_twitter',\n",
    "       'hashtag_volume_twitter', 'keyword_volume_twitter',\n",
    "       'cashtag_volume_twitter', 'avg_tweet_interaction_twitter',\n",
    "       'media_count_c_instagram', 'media_count_instagram',\n",
    "       'tracked_posts_c_instagram', 'tracked_posts_instagram',\n",
    "       'followed_by_count_c_instagram', 'followed_by_count_instagram',\n",
    "       'follows_count_c_instagram', 'follows_count_instagram',\n",
    "       'total_likes_c_instagram', 'total_likes_instagram',\n",
    "       'total_comments_c_instagram', 'total_comments_instagram',\n",
    "       'total_post_interactions_c_instagram',\n",
    "       'total_post_interactions_instagram',\n",
    "       'avg_interactions_per_post_c_instagram',\n",
    "       'avg_interactions_per_post_instagram']\n",
    "\n",
    "\n",
    "# apply standardization on numerical features\n",
    "    \n",
    "for i in num_cols:\n",
    "    \n",
    "    # fit on training data column\n",
    "    scale = MinMaxScaler().fit(movies_test_normalize[[i]])\n",
    "    \n",
    "    # transform the training data column\n",
    "    movies_test_normalize[i] = scale.transform(movies_test_normalize[[i]])\n",
    "    \n",
    "    # transform the testing data column\n",
    "    movies_test_normalize[i] = scale.transform(movies_test_normalize[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Specs      Score\n",
      "4                       inflated_budget  11.378469\n",
      "1                                source   6.771801\n",
      "19       total_post_comments_c_facebook   5.246370\n",
      "25     total_post_haha_count_c_facebook   4.723727\n",
      "10               talking_about_facebook   4.503240\n",
      "12             engagement_rate_facebook   4.497621\n",
      "69               hashtag_volume_twitter   4.480371\n",
      "88  avg_interactions_per_post_instagram   4.028047\n",
      "26       total_post_haha_count_facebook   3.939283\n",
      "2                             franchise   3.861086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "X = movies_test_normalize.iloc[:,0:89]  #independent columns\n",
    "y = movies_test_normalize.iloc[:,-1]    #target column i.e price range\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_test_normalize_sel = movies_test_normalize[['inflated_budget',\n",
    "                               'source',\n",
    "       'total_post_comments_c_facebook',\n",
    "     'total_post_haha_count_c_facebook',\n",
    "                'talking_about_facebook',\n",
    "              'engagement_rate_facebook',\n",
    "               'hashtag_volume_twitter',\n",
    "  'avg_interactions_per_post_instagram',\n",
    "       'total_post_haha_count_facebook',\n",
    "               'franchise',\n",
    "                'successflop']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# test_size: what proportion of original data is used for test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "   movies_test_normalize_sel.loc[:,movies_test_normalize_sel.columns != 'successflop'] ,movies_test_normalize_sel[['successflop']], random_state=1234, test_size=0.30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.2654, 'total_post_comments_c_facebook'), (0.2238, 'engagement_rate_facebook'), (0.1787, 'hashtag_volume_twitter'), (0.1749, 'total_post_haha_count_c_facebook'), (0.0585, 'source'), (0.056, 'avg_interactions_per_post_instagram'), (0.0284, 'franchise'), (0.0126, 'total_post_haha_count_facebook'), (0.0018, 'talking_about_facebook'), (0.0, 'inflated_budget')]\n"
     ]
    }
   ],
   "source": [
    "# Variable importance\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "print( \"Features sorted by their score:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), x_train), reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_post_comments_c_facebook</td>\n",
       "      <td>0.265370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>engagement_rate_facebook</td>\n",
       "      <td>0.223774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hashtag_volume_twitter</td>\n",
       "      <td>0.178678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>total_post_haha_count_c_facebook</td>\n",
       "      <td>0.174901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>source</td>\n",
       "      <td>0.058473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>avg_interactions_per_post_instagram</td>\n",
       "      <td>0.055995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>franchise</td>\n",
       "      <td>0.028389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total_post_haha_count_facebook</td>\n",
       "      <td>0.012613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>talking_about_facebook</td>\n",
       "      <td>0.001807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inflated_budget</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              features  importance\n",
       "2       total_post_comments_c_facebook    0.265370\n",
       "5             engagement_rate_facebook    0.223774\n",
       "6               hashtag_volume_twitter    0.178678\n",
       "3     total_post_haha_count_c_facebook    0.174901\n",
       "1                               source    0.058473\n",
       "7  avg_interactions_per_post_instagram    0.055995\n",
       "9                            franchise    0.028389\n",
       "8       total_post_haha_count_facebook    0.012613\n",
       "4               talking_about_facebook    0.001807\n",
       "0                      inflated_budget    0.000000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'features' : x_train.columns.to_numpy(), 'importance':rf.feature_importances_}).sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "logistic_model = LogisticRegression(random_state = 0)\n",
    "# Model Fitting on Training\n",
    "logistic_model = logistic_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(logistic_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(logistic_model.predict_proba(x_test))\n",
    "\n",
    "logistic_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "logistic_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "logistic_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "logistic_class_report = metrics.classification_report(y_test, predicted)\n",
    "logistic_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "logistic_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "logistic_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "logistic_cv_score = cross_val_score(LogisticRegression(), x_test, y_test, scoring='accuracy', cv=10)\n",
    "logistic_cv_mean = np.mean(logistic_cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "dtree_model = tree.DecisionTreeClassifier(max_depth=3) \n",
    "# Model Fitting on Training\n",
    "dtree_model = dtree_model.fit(x_train, y_train)\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(dtree_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(dtree_model.predict_proba(x_test))\n",
    "\n",
    "dtree_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "dtree_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "dtree_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "dtree_class_report = metrics.classification_report(y_test, predicted)\n",
    "dtree_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "dtree_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "dtree_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "dtree_cv_score = cross_val_score(tree.DecisionTreeClassifier(max_depth=3), x_test, y_test, scoring='accuracy', cv=10)\n",
    "dtree_cv_mean = np.mean(dtree_cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6786764705882353"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Model\n",
    "rf = RandomForestClassifier() \n",
    "# Model Fitting on Training\n",
    "rf_model = rf.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(rf_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(rf_model.predict_proba(x_test))\n",
    "\n",
    "rf_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "rf_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "rf_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "rf_class_report = metrics.classification_report(y_test, predicted)\n",
    "rf_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "rf_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "rf_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "rf_cv_scores = cross_val_score(RandomForestClassifier(), x_test, y_test, scoring='accuracy', cv=10)\n",
    "rf_cv_mean = np.mean(rf_cv_scores)\n",
    "rf_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6911764705882353"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Model\n",
    "svm_class_model = SVC(probability=True)\n",
    "# Model Fitting on Training\n",
    "svm_class_model = svm_class_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(svm_class_model.predict(x_test))\n",
    "probs = pd.DataFrame(svm_class_model.predict_proba(x_test))\n",
    "\n",
    "# Store metrics\n",
    "svm_class_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "svm_class_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "svm_class_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "svm_class_class_report = metrics.classification_report(y_test, predicted)\n",
    "svm_class_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "svm_class_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "svm_class_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "svm_class_cv_scores = cross_val_score(SVC(probability=True), x_test, y_test, scoring='accuracy', cv=10)\n",
    "svm_class_cv_mean = np.mean(svm_class_cv_scores)\n",
    "svm_class_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6242647058823529"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "# Model Fitting on Training\n",
    "knn_model.fit(x_train, y_train)\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(knn_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(knn_model.predict_proba(x_test))\n",
    "\n",
    "knn_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "knn_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "knn_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "knn_class_report = metrics.classification_report(y_test, predicted)\n",
    "knn_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "knn_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "knn_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "knn_cv_scores = cross_val_score(KNeighborsClassifier(n_neighbors=3), x_test, y_test, scoring='accuracy', cv=10)\n",
    "knn_cv_mean = np.mean(knn_cv_scores)\n",
    "knn_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(10, 10, 1))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Model\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(10,10,1))\n",
    "# Model Fitting on Training\n",
    "mlp_model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=MLPClassifier(max_iter=5000), n_jobs=-1,\n",
       "             param_grid={'activation': ['logistic', 'relu'],\n",
       "                         'alpha': [0.0001, 0.05, 0.01, 0.001, 0.005, 0.0005],\n",
       "                         'hidden_layer_sizes': [(10, 10, 50, 1), (10, 5, 1),\n",
       "                                                (10, 10, 1)],\n",
       "                         'learning_rate': ['constant', 'adaptive'],\n",
       "                         'solver': ['sgd', 'adam']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Model for GridSearchCV\n",
    "mlp_model = MLPClassifier(max_iter=5000)\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(10,10,50,1), (10,5,1), (10,10,1)],\n",
    "    'activation': ['logistic', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05,  0.01, 0.001, 0.005, 0.0005],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mlp_cv = GridSearchCV(mlp_model, parameter_space, n_jobs=-1, cv=10, scoring = 'accuracy')\n",
    "mlp_cv.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.365087</td>\n",
       "      <td>6.333686</td>\n",
       "      <td>0.071909</td>\n",
       "      <td>0.041098</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(10, 10, 50, 1)</td>\n",
       "      <td>constant</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0001, 'h...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.701351</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.857747</td>\n",
       "      <td>18.826796</td>\n",
       "      <td>0.070974</td>\n",
       "      <td>0.037907</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(10, 10, 50, 1)</td>\n",
       "      <td>constant</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0001, 'h...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.701351</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.883553</td>\n",
       "      <td>0.333414</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(10, 10, 1)</td>\n",
       "      <td>constant</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.05, 'hidden_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.701351</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1.390948</td>\n",
       "      <td>1.697809</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(10, 10, 1)</td>\n",
       "      <td>constant</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.05, 'hidden_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.701351</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.449514</td>\n",
       "      <td>0.223427</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(10, 10, 1)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.05, 'hidden_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.701351</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3.543766</td>\n",
       "      <td>4.754412</td>\n",
       "      <td>0.011845</td>\n",
       "      <td>0.021952</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(10, 10, 1)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.05, 'hidden_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.701351</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.726312</td>\n",
       "      <td>4.839846</td>\n",
       "      <td>0.042288</td>\n",
       "      <td>0.043408</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(10, 10, 50, 1)</td>\n",
       "      <td>constant</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.701351</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>8.357056</td>\n",
       "      <td>7.777122</td>\n",
       "      <td>0.051558</td>\n",
       "      <td>0.041268</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(10, 10, 50, 1)</td>\n",
       "      <td>constant</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.701351</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>11.516268</td>\n",
       "      <td>5.381242</td>\n",
       "      <td>0.043023</td>\n",
       "      <td>0.040588</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(10, 10, 50, 1)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.701351</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>7.571556</td>\n",
       "      <td>7.123069</td>\n",
       "      <td>0.041085</td>\n",
       "      <td>0.042889</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(10, 10, 50, 1)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.701351</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        8.365087      6.333686         0.071909        0.041098   \n",
       "1       18.857747     18.826796         0.070974        0.037907   \n",
       "92       0.883553      0.333414         0.003223        0.000382   \n",
       "93       1.390948      1.697809         0.003753        0.001427   \n",
       "94       0.449514      0.223427         0.002928        0.000086   \n",
       "95       3.543766      4.754412         0.011845        0.021952   \n",
       "96       5.726312      4.839846         0.042288        0.043408   \n",
       "97       8.357056      7.777122         0.051558        0.041268   \n",
       "98      11.516268      5.381242         0.043023        0.040588   \n",
       "99       7.571556      7.123069         0.041085        0.042889   \n",
       "\n",
       "   param_activation param_alpha param_hidden_layer_sizes param_learning_rate  \\\n",
       "0          logistic      0.0001          (10, 10, 50, 1)            constant   \n",
       "1          logistic      0.0001          (10, 10, 50, 1)            constant   \n",
       "92             relu        0.05              (10, 10, 1)            constant   \n",
       "93             relu        0.05              (10, 10, 1)            constant   \n",
       "94             relu        0.05              (10, 10, 1)            adaptive   \n",
       "95             relu        0.05              (10, 10, 1)            adaptive   \n",
       "96             relu        0.01          (10, 10, 50, 1)            constant   \n",
       "97             relu        0.01          (10, 10, 50, 1)            constant   \n",
       "98             relu        0.01          (10, 10, 50, 1)            adaptive   \n",
       "99             relu        0.01          (10, 10, 50, 1)            adaptive   \n",
       "\n",
       "   param_solver                                             params  ...  \\\n",
       "0           sgd  {'activation': 'logistic', 'alpha': 0.0001, 'h...  ...   \n",
       "1          adam  {'activation': 'logistic', 'alpha': 0.0001, 'h...  ...   \n",
       "92          sgd  {'activation': 'relu', 'alpha': 0.05, 'hidden_...  ...   \n",
       "93         adam  {'activation': 'relu', 'alpha': 0.05, 'hidden_...  ...   \n",
       "94          sgd  {'activation': 'relu', 'alpha': 0.05, 'hidden_...  ...   \n",
       "95         adam  {'activation': 'relu', 'alpha': 0.05, 'hidden_...  ...   \n",
       "96          sgd  {'activation': 'relu', 'alpha': 0.01, 'hidden_...  ...   \n",
       "97         adam  {'activation': 'relu', 'alpha': 0.01, 'hidden_...  ...   \n",
       "98          sgd  {'activation': 'relu', 'alpha': 0.01, 'hidden_...  ...   \n",
       "99         adam  {'activation': 'relu', 'alpha': 0.01, 'hidden_...  ...   \n",
       "\n",
       "    split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0            0.710526           0.710526           0.702703   \n",
       "1            0.710526           0.710526           0.702703   \n",
       "92           0.710526           0.710526           0.702703   \n",
       "93           0.710526           0.710526           0.702703   \n",
       "94           0.710526           0.710526           0.702703   \n",
       "95           0.710526           0.710526           0.702703   \n",
       "96           0.710526           0.710526           0.702703   \n",
       "97           0.710526           0.710526           0.702703   \n",
       "98           0.710526           0.710526           0.702703   \n",
       "99           0.710526           0.710526           0.702703   \n",
       "\n",
       "    split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0            0.702703           0.702703           0.702703   \n",
       "1            0.702703           0.702703           0.702703   \n",
       "92           0.702703           0.702703           0.702703   \n",
       "93           0.702703           0.702703           0.702703   \n",
       "94           0.702703           0.702703           0.702703   \n",
       "95           0.702703           0.702703           0.702703   \n",
       "96           0.702703           0.702703           0.702703   \n",
       "97           0.702703           0.702703           0.702703   \n",
       "98           0.702703           0.702703           0.702703   \n",
       "99           0.702703           0.702703           0.702703   \n",
       "\n",
       "    split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.702703         0.701351        0.009216                1  \n",
       "1            0.702703         0.701351        0.009216                1  \n",
       "92           0.702703         0.701351        0.009216                1  \n",
       "93           0.702703         0.701351        0.009216                1  \n",
       "94           0.702703         0.701351        0.009216                1  \n",
       "95           0.702703         0.701351        0.009216                1  \n",
       "96           0.702703         0.701351        0.009216                1  \n",
       "97           0.702703         0.701351        0.009216                1  \n",
       "98           0.702703         0.701351        0.009216                1  \n",
       "99           0.702703         0.701351        0.009216                1  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mlp_cv.cv_results_).sort_values('mean_test_score', ascending = False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.575"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using best model parameters to model\n",
    "\n",
    "# Initiate Model\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(10,10,50, 1), activation = 'logistic', solver = 'sgd', alpha = 0.0001, \n",
    "                          learning_rate = 'constant')\n",
    "# Model Fitting on Training\n",
    "mlp_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(mlp_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(mlp_model.predict_proba(x_test))\n",
    "\n",
    "mlp_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "mlp_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "mlp_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "mlp_class_report = metrics.classification_report(y_test, predicted)\n",
    "mlp_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "mlp_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "mlp_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "mlp_cv_scores = cross_val_score(mlp_model, x_test, y_test, scoring='accuracy', cv=10)\n",
    "mlp_cv_mean = np.mean(mlp_cv_scores)\n",
    "mlp_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>cv_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817518</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817518</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r.f.</td>\n",
       "      <td>0.672840</td>\n",
       "      <td>0.703448</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.793774</td>\n",
       "      <td>0.678676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d.Tree</td>\n",
       "      <td>0.697531</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.659926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.586420</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.714894</td>\n",
       "      <td>0.624265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817518</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy  Precision    recall        F1  cv_accuracy\n",
       "0  Logistic  0.691358   0.691358  1.000000  0.817518     0.691176\n",
       "3       SVM  0.691358   0.691358  1.000000  0.817518     0.691176\n",
       "2      r.f.  0.672840   0.703448  0.910714  0.793774     0.678676\n",
       "1    d.Tree  0.697531   0.695652  1.000000  0.820513     0.659926\n",
       "4       kNN  0.586420   0.682927  0.750000  0.714894     0.624265\n",
       "5       MLP  0.691358   0.691358  1.000000  0.817518     0.575000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model comparison\n",
    "models = pd.DataFrame({\n",
    "  'Model': ['Logistic', 'd.Tree', 'r.f.', 'SVM', 'kNN',  'MLP'],\n",
    "  'Accuracy' : [logistic_acc, dtree_acc, rf_acc, svm_class_acc, knn_acc, mlp_acc],\n",
    "  'Precision': [logistic_precision_score, dtree_precision_score, rf_precision_score, svm_class_precision_score, knn_precision_score, mlp_precision_score],\n",
    "  'recall' : [logistic_recall_score, dtree_recall_score, rf_recall_score, svm_class_recall_score, knn_recall_score, mlp_recall_score],\n",
    "  'F1' : [logistic_f1_score, dtree_f1_score, rf_f1_score, svm_class_f1_score, knn_f1_score, mlp_f1_score],\n",
    "  'cv_accuracy' : [logistic_cv_mean, dtree_cv_mean, rf_cv_mean, svm_class_cv_mean, knn_cv_mean, mlp_cv_mean]\n",
    "})\n",
    "# Print table and sort by test precision\n",
    "models.sort_values(by='cv_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using KS Score for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def ks_score(df, label_col, pos_lab, neg_lab):\n",
    "    columns = [x for x in df.columns[2:]]\n",
    "    stat = [stats.ks_2samp(df[df[label_col] == pos_lab][x], df[df[label_col] == neg_lab][x])[0] for x in df.columns[2:]]\n",
    "    pvalue = [stats.ks_2samp(df[df[label_col] == pos_lab][x], df[df[label_col] == neg_lab][x])[1] for x in df.columns[2:]]\n",
    "    ks_df = pd.DataFrame(list(zip(columns,stat, pvalue)), columns =['variable', 'ks_stat', 'p_value'])\n",
    "    return(ks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_sel = movies_fil[['brand_ods_id', 'rating', 'source', 'franchise', 'genre_grouped',\n",
    "       'inflated_budget', 'production_company_bin',\n",
    "       'released_month', 'released_on', 'successflop']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_filled = fb.fillna(0)\n",
    "\n",
    "fb_output = pd.merge(fb_filled, movies_sel, left_on = 'movie_id', right_on = 'brand_ods_id', how = 'left')\n",
    "fb_output = fb_output.dropna(subset=['brand_ods_id'])\n",
    "fb_output['data_for']= pd.to_datetime(fb_output['data_for']) \n",
    "fb_output['released_on'] = pd.to_datetime(fb_output['released_on'])\n",
    "fb_output['days_after_release'] = fb_output['data_for'] - fb_output['released_on']\n",
    "fb_output = fb_output[(fb_output['days_after_release'] <= '0 days') & (fb_output['days_after_release'] >= '-365 days')]\n",
    "fb_output['days_after_release'] = fb_output['days_after_release'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_output.to_csv('toby_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_mean = fb_output.groupby(['successflop','days_after_release'], as_index = False).agg('mean').drop(\n",
    "    ['movie_id', 'brand_ods_id',\n",
    "       'inflated_budget', 'released_month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>ks_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>total_post_haha_count_facebook</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>4.752606e-199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>total_post_thankful_count_facebook</td>\n",
       "      <td>0.931694</td>\n",
       "      <td>5.243957e-173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>total_post_sad_count_facebook</td>\n",
       "      <td>0.691257</td>\n",
       "      <td>7.173386e-84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>total_post_video_facebook</td>\n",
       "      <td>0.685792</td>\n",
       "      <td>2.093151e-82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>total_post_angry_count_facebook</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.039688e-77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              variable   ks_stat        p_value\n",
       "19      total_post_haha_count_facebook  0.975410  4.752606e-199\n",
       "25  total_post_thankful_count_facebook  0.931694  5.243957e-173\n",
       "21       total_post_sad_count_facebook  0.691257   7.173386e-84\n",
       "33           total_post_video_facebook  0.685792   2.093151e-82\n",
       "23     total_post_angry_count_facebook  0.666667   2.039688e-77"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_var_score = ks_score(fb_mean, 'successflop', 'Success', 'Flop')\n",
    "fb_var_score.sort_values('ks_stat', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "insta_filled = instagram.fillna(0)\n",
    "\n",
    "insta_output = pd.merge(insta_filled, movies_sel, left_on = 'movie_id', right_on = 'brand_ods_id', how = 'left')\n",
    "insta_output = insta_output.dropna(subset=['brand_ods_id'])\n",
    "insta_output['data_for']= pd.to_datetime(insta_output['data_for']) \n",
    "insta_output['released_on'] = pd.to_datetime(insta_output['released_on'])\n",
    "insta_output['days_after_release'] = insta_output['data_for'] - insta_output['released_on']\n",
    "insta_output = insta_output[(insta_output['days_after_release'] <= '0 days') & (insta_output['days_after_release'] >= '-365 days')]\n",
    "insta_output['days_after_release'] = insta_output['days_after_release'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "insta_mean = insta_output.groupby(['successflop','days_after_release'], as_index = False).agg('mean').drop(\n",
    "    ['movie_id', 'brand_ods_id',\n",
    "       'inflated_budget', 'released_month'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>ks_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tracked_posts_instagram</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>6.668775e-65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>avg_interactions_per_post_instagram</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>6.668775e-65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>follows_count_instagram</td>\n",
       "      <td>0.554645</td>\n",
       "      <td>4.012996e-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>followed_by_count_instagram</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>3.331366e-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>followed_by_count_c_instagram</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>6.915406e-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               variable   ks_stat       p_value\n",
       "3               tracked_posts_instagram  0.614754  6.668775e-65\n",
       "15  avg_interactions_per_post_instagram  0.614754  6.668775e-65\n",
       "7               follows_count_instagram  0.554645  4.012996e-52\n",
       "5           followed_by_count_instagram  0.426230  3.331366e-30\n",
       "4         followed_by_count_c_instagram  0.409836  6.915406e-28"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insta_var_score = ks_score(insta_mean, 'successflop', 'Success', 'Flop')\n",
    "insta_var_score.sort_values('ks_stat', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_filled = twitter.fillna(0)\n",
    "\n",
    "twitter_output = pd.merge(twitter_filled, movies_sel, left_on = 'movie_id', right_on = 'brand_ods_id', how = 'left')\n",
    "twitter_output = twitter_output.dropna(subset=['brand_ods_id'])\n",
    "twitter_output['data_for']= pd.to_datetime(insta_output['data_for']) \n",
    "twitter_output['released_on'] = pd.to_datetime(insta_output['released_on'])\n",
    "twitter_output['days_after_release'] = twitter_output['data_for'] - twitter_output['released_on']\n",
    "twitter_output = twitter_output[(twitter_output['days_after_release'] <= '0 days') & (twitter_output['days_after_release'] >= '-365 days')]\n",
    "twitter_output['days_after_release'] = twitter_output['days_after_release'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_mean = twitter_output.groupby(['successflop','days_after_release'], as_index = False).agg('mean').drop(\n",
    "    ['movie_id', 'brand_ods_id',\n",
    "       'inflated_budget', 'released_month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>ks_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>avg_tweet_interaction_twitter</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.002873e-219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>video_replies_twitter</td>\n",
       "      <td>0.980874</td>\n",
       "      <td>6.519101e-203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>total_replies_twitter</td>\n",
       "      <td>0.928962</td>\n",
       "      <td>1.425953e-171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>video_views_twitter</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>5.340549e-166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_retweets_twitter</td>\n",
       "      <td>0.890710</td>\n",
       "      <td>4.731581e-153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         variable   ks_stat        p_value\n",
       "29  avg_tweet_interaction_twitter  1.000000  3.002873e-219\n",
       "21          video_replies_twitter  0.980874  6.519101e-203\n",
       "11          total_replies_twitter  0.928962  1.425953e-171\n",
       "23            video_views_twitter  0.918033  5.340549e-166\n",
       "7          total_retweets_twitter  0.890710  4.731581e-153"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_var_score = ks_score(twitter_mean, 'successflop', 'Success', 'Flop')\n",
    "twitter_var_score.sort_values('ks_stat', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing features and trying models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_ks_sel = movies_final[['inflated_budget',\n",
    "                            'total_post_haha_count_facebook',\n",
    "                              'total_post_thankful_count_facebook',\n",
    "                              'total_post_sad_count_facebook',\n",
    "                              'total_post_video_facebook',\n",
    "                              'total_post_angry_count_facebook',\n",
    "                              'tracked_posts_instagram',\n",
    "                              'avg_interactions_per_post_instagram',\n",
    "                              'follows_count_instagram',\n",
    "                              'followed_by_count_instagram',\n",
    "                              'followed_by_count_c_instagram',\n",
    "                              'avg_tweet_interaction_twitter',\n",
    "                                'video_replies_twitter',\n",
    "                                'total_replies_twitter',\n",
    "                                  'video_views_twitter',\n",
    "                                'total_retweets_twitter',\n",
    "                             'successflop']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting Dataset into train and test\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "   movies_ks_sel.loc[:,movies_ks_sel.columns != 'successflop'] ,movies_ks_sel[['successflop']], random_state=1234, test_size=0.30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inflated_budget</td>\n",
       "      <td>0.193152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>total_retweets_twitter</td>\n",
       "      <td>0.113615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>avg_tweet_interaction_twitter</td>\n",
       "      <td>0.107268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_post_video_facebook</td>\n",
       "      <td>0.100288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tracked_posts_instagram</td>\n",
       "      <td>0.067022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_post_haha_count_facebook</td>\n",
       "      <td>0.056126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>avg_interactions_per_post_instagram</td>\n",
       "      <td>0.054853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>total_post_angry_count_facebook</td>\n",
       "      <td>0.053979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>follows_count_instagram</td>\n",
       "      <td>0.046308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>followed_by_count_c_instagram</td>\n",
       "      <td>0.042162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>followed_by_count_instagram</td>\n",
       "      <td>0.042084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>total_post_sad_count_facebook</td>\n",
       "      <td>0.041264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>video_views_twitter</td>\n",
       "      <td>0.028841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>video_replies_twitter</td>\n",
       "      <td>0.019806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>total_replies_twitter</td>\n",
       "      <td>0.018829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_post_thankful_count_facebook</td>\n",
       "      <td>0.014401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               features  importance\n",
       "0                       inflated_budget    0.193152\n",
       "15               total_retweets_twitter    0.113615\n",
       "11        avg_tweet_interaction_twitter    0.107268\n",
       "4             total_post_video_facebook    0.100288\n",
       "6               tracked_posts_instagram    0.067022\n",
       "1        total_post_haha_count_facebook    0.056126\n",
       "7   avg_interactions_per_post_instagram    0.054853\n",
       "5       total_post_angry_count_facebook    0.053979\n",
       "8               follows_count_instagram    0.046308\n",
       "10        followed_by_count_c_instagram    0.042162\n",
       "9           followed_by_count_instagram    0.042084\n",
       "3         total_post_sad_count_facebook    0.041264\n",
       "14                  video_views_twitter    0.028841\n",
       "12                video_replies_twitter    0.019806\n",
       "13                total_replies_twitter    0.018829\n",
       "2    total_post_thankful_count_facebook    0.014401"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Variable importance for Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "pd.DataFrame({'features' : x_train.columns.to_numpy(), 'importance':rf.feature_importances_}).sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "logistic_model = LogisticRegression(random_state = 0)\n",
    "# Model Fitting on Training\n",
    "logistic_model = logistic_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(logistic_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(logistic_model.predict_proba(x_test))\n",
    "\n",
    "logistic_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "logistic_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "logistic_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "logistic_class_report = metrics.classification_report(y_test, predicted)\n",
    "logistic_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "logistic_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "logistic_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "logistic_cv_score = cross_val_score(LogisticRegression(), x_test, y_test, scoring='accuracy', cv=10)\n",
    "logistic_cv_mean = np.mean(logistic_cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,  49],\n",
       "       [  1, 111]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "dtree_model = tree.DecisionTreeClassifier(max_depth=3) \n",
    "\n",
    "# Model Fitting on Training\n",
    "dtree_model = dtree_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(dtree_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(dtree_model.predict_proba(x_test))\n",
    "\n",
    "dtree_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "dtree_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "dtree_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "dtree_class_report = metrics.classification_report(y_test, predicted)\n",
    "dtree_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "dtree_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "dtree_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "dtree_cv_score = cross_val_score(tree.DecisionTreeClassifier(max_depth=3), x_test, y_test, scoring='accuracy', cv=10)\n",
    "dtree_cv_mean = np.mean(dtree_cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "rf_model = RandomForestClassifier() \n",
    "\n",
    "# Model Fitting on Training\n",
    "rf_model = rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(rf_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(rf_model.predict_proba(x_test))\n",
    "\n",
    "rf_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "rf_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "rf_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "rf_class_report = metrics.classification_report(y_test, predicted)\n",
    "rf_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "rf_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "rf_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "rf_cv_scores = cross_val_score(RandomForestClassifier(), x_test, y_test, scoring='accuracy', cv=10)\n",
    "rf_cv_mean = np.mean(rf_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "\n",
    "svm_class_model = SVC(probability=True)\n",
    "\n",
    "# Model Fitting on Training\n",
    "svm_class_model = svm_class_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(svm_class_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(svm_class_model.predict_proba(x_test))\n",
    "\n",
    "svm_class_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "svm_class_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "svm_class_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "svm_class_class_report = metrics.classification_report(y_test, predicted)\n",
    "svm_class_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "svm_class_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "svm_class_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "svm_class_cv_scores = cross_val_score(SVC(probability=True), x_test, y_test, scoring='accuracy', cv=10)\n",
    "svm_class_cv_mean = np.mean(svm_class_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.505909090909091"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Model Fitting on Training\n",
    "knn_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(knn_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(knn_model.predict_proba(x_test))\n",
    "\n",
    "knn_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "knn_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "knn_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "knn_class_report = metrics.classification_report(y_test, predicted)\n",
    "knn_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "knn_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "knn_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "knn_cv_scores = cross_val_score(KNeighborsClassifier(n_neighbors=3), x_test, y_test, scoring='balanced_accuracy', cv=10)\n",
    "knn_cv_mean = np.mean(knn_cv_scores)\n",
    "knn_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2986666666666667"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(10,10, 1))\n",
    "# Fit the model\n",
    "mlp_model.fit(x_train, y_train)\n",
    "# Accuracy\n",
    "mlp_model.score(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54375"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions/probs on the test dataset\n",
    "predicted = pd.DataFrame(mlp_model.predict(x_test))\n",
    "probs = pd.DataFrame(mlp_model.predict_proba(x_test))\n",
    "\n",
    "mlp_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "mlp_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "mlp_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "mlp_class_report = metrics.classification_report(y_test, predicted)\n",
    "mlp_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "mlp_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "mlp_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "mlp_cv_scores = cross_val_score(mlp_model, x_test, y_test, scoring='accuracy', cv=10)\n",
    "mlp_cv_mean = np.mean(mlp_cv_scores)\n",
    "mlp_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>cv_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817518</td>\n",
       "      <td>0.678676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r.f.</td>\n",
       "      <td>0.697531</td>\n",
       "      <td>0.717241</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.809339</td>\n",
       "      <td>0.616544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d.Tree</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.585294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.991071</td>\n",
       "      <td>0.816176</td>\n",
       "      <td>0.580515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.308642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.543750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.866071</td>\n",
       "      <td>0.791837</td>\n",
       "      <td>0.505909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy  Precision    recall        F1  cv_accuracy\n",
       "3       SVM  0.691358   0.691358  1.000000  0.817518     0.678676\n",
       "2      r.f.  0.697531   0.717241  0.928571  0.809339     0.616544\n",
       "1    d.Tree  0.691358   0.696203  0.982143  0.814815     0.585294\n",
       "0  Logistic  0.691358   0.693750  0.991071  0.816176     0.580515\n",
       "5       MLP  0.308642   0.000000  0.000000  0.000000     0.543750\n",
       "4       kNN  0.685185   0.729323  0.866071  0.791837     0.505909"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model comparison\n",
    "models = pd.DataFrame({\n",
    "  'Model': ['Logistic', 'd.Tree', 'r.f.', 'SVM', 'kNN',  'MLP'],\n",
    "  'Accuracy' : [logistic_acc, dtree_acc, rf_acc, svm_class_acc, knn_acc, mlp_acc],\n",
    "  'Precision': [logistic_precision_score, dtree_precision_score, rf_precision_score, svm_class_precision_score, knn_precision_score, mlp_precision_score],\n",
    "  'recall' : [logistic_recall_score, dtree_recall_score, rf_recall_score, svm_class_recall_score, knn_recall_score, mlp_recall_score],\n",
    "  'F1' : [logistic_f1_score, dtree_f1_score, rf_f1_score, svm_class_f1_score, knn_f1_score, mlp_f1_score],\n",
    "  'cv_accuracy' : [logistic_cv_mean, dtree_cv_mean, rf_cv_mean, svm_class_cv_mean, knn_cv_mean, mlp_cv_mean]\n",
    "})\n",
    "# Print table and sort by test precision\n",
    "models.sort_values(by='cv_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_ks_normalize = movies_ks_sel.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cols = ['inflated_budget',\n",
    "                            'total_post_haha_count_facebook',\n",
    "                              'total_post_thankful_count_facebook',\n",
    "                              'total_post_sad_count_facebook',\n",
    "                              'total_post_video_facebook',\n",
    "                              'total_post_angry_count_facebook',\n",
    "                              'tracked_posts_instagram',\n",
    "                              'avg_interactions_per_post_instagram',\n",
    "                              'follows_count_instagram',\n",
    "                              'followed_by_count_instagram',\n",
    "                              'followed_by_count_c_instagram',\n",
    "                              'avg_tweet_interaction_twitter',\n",
    "                                'video_replies_twitter',\n",
    "                                'total_replies_twitter',\n",
    "                                  'video_views_twitter',\n",
    "                                'total_retweets_twitter',]\n",
    "\n",
    "\n",
    "# apply standardization on numerical features\n",
    "    \n",
    "for i in num_cols:\n",
    "    \n",
    "    # fit on training data column\n",
    "    scale = MinMaxScaler().fit(movies_ks_normalize[[i]])\n",
    "    \n",
    "    # transform the training data column\n",
    "    movies_ks_normalize[i] = scale.transform(movies_ks_normalize[[i]])\n",
    "    \n",
    "    # transform the testing data column\n",
    "    movies_ks_normalize[i] = scale.transform(movies_ks_normalize[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_size: what proportion of original data is used for test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "   movies_ks_normalize.loc[:,movies_ks_normalize.columns != 'successflop'] ,movies_ks_normalize[['successflop']], random_state=1234, test_size=0.30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.2106, 'total_post_video_facebook'), (0.1776, 'tracked_posts_instagram'), (0.1686, 'followed_by_count_c_instagram'), (0.1137, 'total_post_thankful_count_facebook'), (0.091, 'video_replies_twitter'), (0.0665, 'avg_interactions_per_post_instagram'), (0.0487, 'follows_count_instagram'), (0.0352, 'total_replies_twitter'), (0.0317, 'avg_tweet_interaction_twitter'), (0.0274, 'total_post_angry_count_facebook'), (0.0232, 'total_post_haha_count_facebook'), (0.0056, 'total_post_sad_count_facebook'), (0.0, 'video_views_twitter'), (0.0, 'total_retweets_twitter'), (0.0, 'inflated_budget'), (0.0, 'followed_by_count_instagram')]\n"
     ]
    }
   ],
   "source": [
    "# Variable importance\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "print( \"Features sorted by their score:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), x_train), reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_post_video_facebook</td>\n",
       "      <td>0.210583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tracked_posts_instagram</td>\n",
       "      <td>0.177626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>followed_by_count_c_instagram</td>\n",
       "      <td>0.168621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_post_thankful_count_facebook</td>\n",
       "      <td>0.113736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>video_replies_twitter</td>\n",
       "      <td>0.090960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>avg_interactions_per_post_instagram</td>\n",
       "      <td>0.066537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>follows_count_instagram</td>\n",
       "      <td>0.048738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>total_replies_twitter</td>\n",
       "      <td>0.035213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>avg_tweet_interaction_twitter</td>\n",
       "      <td>0.031749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>total_post_angry_count_facebook</td>\n",
       "      <td>0.027438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_post_haha_count_facebook</td>\n",
       "      <td>0.023232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>total_post_sad_count_facebook</td>\n",
       "      <td>0.005568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inflated_budget</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>followed_by_count_instagram</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>video_views_twitter</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>total_retweets_twitter</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               features  importance\n",
       "4             total_post_video_facebook    0.210583\n",
       "6               tracked_posts_instagram    0.177626\n",
       "10        followed_by_count_c_instagram    0.168621\n",
       "2    total_post_thankful_count_facebook    0.113736\n",
       "12                video_replies_twitter    0.090960\n",
       "7   avg_interactions_per_post_instagram    0.066537\n",
       "8               follows_count_instagram    0.048738\n",
       "13                total_replies_twitter    0.035213\n",
       "11        avg_tweet_interaction_twitter    0.031749\n",
       "5       total_post_angry_count_facebook    0.027438\n",
       "1        total_post_haha_count_facebook    0.023232\n",
       "3         total_post_sad_count_facebook    0.005568\n",
       "0                       inflated_budget    0.000000\n",
       "9           followed_by_count_instagram    0.000000\n",
       "14                  video_views_twitter    0.000000\n",
       "15               total_retweets_twitter    0.000000"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'features' : x_train.columns.to_numpy(), 'importance':rf.feature_importances_}).sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "logistic_model = LogisticRegression(random_state = 0)\n",
    "# Model Fitting on Training\n",
    "logistic_model = logistic_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(logistic_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(logistic_model.predict_proba(x_test))\n",
    "\n",
    "logistic_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "logistic_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "logistic_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "logistic_class_report = metrics.classification_report(y_test, predicted)\n",
    "logistic_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "logistic_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "logistic_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "logistic_cv_score = cross_val_score(LogisticRegression(), x_test, y_test, scoring='accuracy', cv=10)\n",
    "logistic_cv_mean = np.mean(logistic_cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Model\n",
    "dtree_model = tree.DecisionTreeClassifier(max_depth=3) \n",
    "# Model Fitting on Training\n",
    "dtree_model = dtree_model.fit(x_train, y_train)\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(dtree_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(dtree_model.predict_proba(x_test))\n",
    "\n",
    "dtree_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "dtree_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "dtree_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "dtree_class_report = metrics.classification_report(y_test, predicted)\n",
    "dtree_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "dtree_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "dtree_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "dtree_cv_score = cross_val_score(tree.DecisionTreeClassifier(max_depth=3), x_test, y_test, scoring='accuracy', cv=10)\n",
    "dtree_cv_mean = np.mean(dtree_cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6599264705882353"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Model\n",
    "rf = RandomForestClassifier() \n",
    "# Model Fitting on Training\n",
    "rf_model = rf.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(rf_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(rf_model.predict_proba(x_test))\n",
    "\n",
    "rf_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "rf_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "rf_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "rf_class_report = metrics.classification_report(y_test, predicted)\n",
    "rf_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "rf_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "rf_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "rf_cv_scores = cross_val_score(RandomForestClassifier(), x_test, y_test, scoring='accuracy', cv=10)\n",
    "rf_cv_mean = np.mean(rf_cv_scores)\n",
    "rf_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6911764705882353"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Model\n",
    "svm_class_model = SVC(probability=True)\n",
    "# Model Fitting on Training\n",
    "svm_class_model = svm_class_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(svm_class_model.predict(x_test))\n",
    "probs = pd.DataFrame(svm_class_model.predict_proba(x_test))\n",
    "\n",
    "# Store metrics\n",
    "svm_class_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "svm_class_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "svm_class_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "svm_class_class_report = metrics.classification_report(y_test, predicted)\n",
    "svm_class_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "svm_class_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "svm_class_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "svm_class_cv_scores = cross_val_score(SVC(probability=True), x_test, y_test, scoring='accuracy', cv=10)\n",
    "svm_class_cv_mean = np.mean(svm_class_cv_scores)\n",
    "svm_class_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5860294117647059"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "# Model Fitting on Training\n",
    "knn_model.fit(x_train, y_train)\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(knn_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(knn_model.predict_proba(x_test))\n",
    "\n",
    "knn_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "knn_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "knn_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "knn_class_report = metrics.classification_report(y_test, predicted)\n",
    "knn_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "knn_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "knn_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "knn_cv_scores = cross_val_score(KNeighborsClassifier(n_neighbors=3), x_test, y_test, scoring='accuracy', cv=10)\n",
    "knn_cv_mean = np.mean(knn_cv_scores)\n",
    "knn_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(10, 10, 1))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate Model\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(10,10,1))\n",
    "# Model Fitting on Training\n",
    "mlp_model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Model for GridSearchCV\n",
    "mlp_model = MLPClassifier(max_iter=5000)\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(10,10,50,1), (10,5,1), (10,10,1)],\n",
    "    'activation': ['logistic', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05,  0.01, 0.001, 0.005, 0.0005],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mlp_cv = GridSearchCV(mlp_model, parameter_space, n_jobs=-1, cv=10, scoring = 'accuracy')\n",
    "mlp_cv.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.DataFrame(mlp_cv.cv_results_).sort_values('mean_test_score', ascending = False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5411764705882354"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using best model parameters to model\n",
    "\n",
    "# Initiate Model\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(10,10,50, 1), activation = 'logistic', solver = 'sgd', alpha = 0.0001, \n",
    "                          learning_rate = 'constant')\n",
    "# Model Fitting on Training\n",
    "mlp_model.fit(x_train, y_train)\n",
    "\n",
    "# Test set predictions\n",
    "predicted = pd.DataFrame(mlp_model.predict(x_test))\n",
    "# Test set prediction probabilities\n",
    "probs = pd.DataFrame(mlp_model.predict_proba(x_test))\n",
    "\n",
    "mlp_acc = metrics.accuracy_score(y_test, predicted)     \n",
    "mlp_AUC = metrics.roc_auc_score(y_test, probs[1])       \n",
    "mlp_confusion = metrics.confusion_matrix(y_test, predicted) \n",
    "mlp_class_report = metrics.classification_report(y_test, predicted)\n",
    "mlp_precision_score = metrics.precision_score(y_test, predicted, pos_label=1)\n",
    "mlp_recall_score = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "mlp_f1_score = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "mlp_cv_scores = cross_val_score(mlp_model, x_test, y_test, scoring='accuracy', cv=10)\n",
    "mlp_cv_mean = np.mean(mlp_cv_scores)\n",
    "mlp_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>cv_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817518</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817518</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r.f.</td>\n",
       "      <td>0.654321</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.659926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d.Tree</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.654779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.586029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817518</td>\n",
       "      <td>0.541176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy  Precision    recall        F1  cv_accuracy\n",
       "0  Logistic  0.691358   0.691358  1.000000  0.817518     0.691176\n",
       "3       SVM  0.691358   0.691358  1.000000  0.817518     0.691176\n",
       "2      r.f.  0.654321   0.679487  0.946429  0.791045     0.659926\n",
       "1    d.Tree  0.679012   0.687500  0.982143  0.808824     0.654779\n",
       "4       kNN  0.629630   0.700000  0.812500  0.752066     0.586029\n",
       "5       MLP  0.691358   0.691358  1.000000  0.817518     0.541176"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model comparison\n",
    "models = pd.DataFrame({\n",
    "  'Model': ['Logistic', 'd.Tree', 'r.f.', 'SVM', 'kNN',  'MLP'],\n",
    "  'Accuracy' : [logistic_acc, dtree_acc, rf_acc, svm_class_acc, knn_acc, mlp_acc],\n",
    "  'Precision': [logistic_precision_score, dtree_precision_score, rf_precision_score, svm_class_precision_score, knn_precision_score, mlp_precision_score],\n",
    "  'recall' : [logistic_recall_score, dtree_recall_score, rf_recall_score, svm_class_recall_score, knn_recall_score, mlp_recall_score],\n",
    "  'F1' : [logistic_f1_score, dtree_f1_score, rf_f1_score, svm_class_f1_score, knn_f1_score, mlp_f1_score],\n",
    "  'cv_accuracy' : [logistic_cv_mean, dtree_cv_mean, rf_cv_mean, svm_class_cv_mean, knn_cv_mean, mlp_cv_mean]\n",
    "})\n",
    "# Print table and sort by test precision\n",
    "models.sort_values(by='cv_accuracy', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
